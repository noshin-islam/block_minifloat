{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Test Runs\n",
        "## Testing using VGG16LP on CIFAR10\n",
        "Training on FP32, Bfloat16, BM5 6 7 8 -\n",
        "\n",
        "Two different formats of each BM config are tested (documented below). Each model was trained thrice and the average evaluation accuracy was taken and plotted in the scatter plot at the end of the section. All these tests have been carried out on VGG16LP, using CIFAR10 dataset, with no data preprocessing techniques used."
      ],
      "metadata": {
        "id": "Z-Pe3Vj9gUYb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dsTcD-G0deO",
        "outputId": "ae3f6231-781c-46c5-d03d-7d41e8c17ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  2 01:00:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG0NoSx_saJB",
        "outputId": "5417dc1c-a778-4e76-ce86-4f1f525a98ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/block_minifloat/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iq6UBB9rR12",
        "outputId": "c3b6f457-f9fb-4ec8-8976-0afa44abae76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/block_minifloat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4SoMy0yuaRy",
        "outputId": "8aa4cc3f-479b-4da5-f9a6-5cc1010b4966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  main.py  Pipfile\t    quant\t   results.txt\n",
            "CIFAR10      models   Pipfile.lock  quant_test.py  utils.py\n",
            "data.py      optim    __pycache__   README.md\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FP32\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME4HeSl5DSSj",
        "outputId": "eb92a336-a1a0-4e28-f17c-bc26ea548682"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w-1-1_a-1-1_e-1-1\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : Default (pytorch fp32)\n",
            "activate  : Default (pytorch fp32)\n",
            "error     : Default (pytorch fp32)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2972   10.3820    24.7965     2.2999   10.0000     3.0424\n",
            "Epoch: 1\n",
            "   2    0.1000     2.2827   11.0880    23.6485\n",
            "Epoch: 2\n",
            "   3    0.1000     2.2854   10.2040    23.6241\n",
            "Epoch: 3\n",
            "   4    0.1000     2.2976    9.9980    23.4490\n",
            "Epoch: 4\n",
            "   5    0.1000     2.2643    9.9300    23.5190     2.3026   10.0000     3.0281\n",
            "Epoch: 5\n",
            "   6    0.1000     2.3026    9.9940    23.4518\n",
            "Epoch: 6\n",
            "   7    0.1000     2.3026    9.9900    23.5369\n",
            "Epoch: 7\n",
            "   8    0.1000     2.3019    9.9980    23.5186\n",
            "Epoch: 8\n",
            "   9    0.1000     2.2262   10.0100    23.4740\n",
            "Epoch: 9\n",
            "  10    0.0965     2.1369   12.3060    23.4866     2.0791   18.4600     3.0214\n",
            "Epoch: 10\n",
            "  11    0.0929     2.0319   19.2860    23.7450\n",
            "Epoch: 11\n",
            "  12    0.0894     1.9075   23.0480    23.4969\n",
            "Epoch: 12\n",
            "  13    0.0859     1.7957   26.9400    23.5326\n",
            "Epoch: 13\n",
            "  14    0.0823     1.7005   31.1960    23.3845\n",
            "Epoch: 14\n",
            "  15    0.0788     1.5905   37.2460    23.5559     1.5013   43.8400     2.9933\n",
            "Epoch: 15\n",
            "  16    0.0752     1.4788   44.5100    23.8110\n",
            "Epoch: 16\n",
            "  17    0.0717     1.3197   52.7280    23.5404\n",
            "Epoch: 17\n",
            "  18    0.0682     1.1851   58.5020    23.5313\n",
            "Epoch: 18\n",
            "  19    0.0646     1.0797   62.7640    23.5501\n",
            "Epoch: 19\n",
            "  20    0.0611     0.9950   66.3180    23.4703     1.0314   66.8800     2.9947\n",
            "Epoch: 20\n",
            "  21    0.0576     0.8958   70.2940    23.4525\n",
            "Epoch: 21\n",
            "  22    0.0540     0.8305   72.9620    23.4894\n",
            "Epoch: 22\n",
            "  23    0.0505     0.7622   75.5400    23.8711\n",
            "Epoch: 23\n",
            "  24    0.0470     0.7065   77.3340    23.5267\n",
            "Epoch: 24\n",
            "  25    0.0434     0.6476   79.0760    23.4408     0.6684   78.9500     2.9806\n",
            "Epoch: 25\n",
            "  26    0.0399     0.6019   80.6700    23.4686\n",
            "Epoch: 26\n",
            "  27    0.0364     0.5627   81.7440    23.3934\n",
            "Epoch: 27\n",
            "  28    0.0328     0.5267   83.1700    23.4131\n",
            "Epoch: 28\n",
            "  29    0.0293     0.4836   84.4480    23.2473\n",
            "Epoch: 29\n",
            "  30    0.0258     0.4590   85.3840    23.6107     0.5297   83.6200     3.0176\n",
            "Epoch: 30\n",
            "  31    0.0222     0.4257   86.2440    24.1944\n",
            "Epoch: 31\n",
            "  32    0.0187     0.3880   87.4500    23.6605\n",
            "Epoch: 32\n",
            "  33    0.0151     0.3567   88.2340    23.6421\n",
            "Epoch: 33\n",
            "  34    0.0116     0.3275   89.3540    23.5402\n",
            "Epoch: 34\n",
            "  35    0.0081     0.3049   90.0640    23.7250     0.4792   85.4800     3.0412\n",
            "Epoch: 35\n",
            "  36    0.0045     0.2813   90.6920    23.6156\n",
            "Epoch: 36\n",
            "  37    0.0010     0.2628   91.2560    23.5869\n",
            "Epoch: 37\n",
            "  38    0.0010     0.2556   91.4020    23.6047\n",
            "Epoch: 38\n",
            "  39    0.0010     0.2568   91.5200    23.8280\n",
            "Epoch: 39\n",
            "  40    0.0010     0.2525   91.6300    23.8911     0.4522   86.3800     3.0494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSN2odxxufGS",
        "outputId": "6ca628c5-2089-41fc-c527-e71231a5ce0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w52_a52_e34\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=2, mantissa=5, tile=48)\n",
            "activate  : BlockMinifloat (exponent=2, mantissa=5, tile=48)\n",
            "error     : BlockMinifloat (exponent=4, mantissa=3, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2273   10.1420    63.3284     2.1293   13.3600     5.9993\n",
            "Epoch: 1\n",
            "   2    0.1000     2.1286   14.0220    62.2226\n",
            "Epoch: 2\n",
            "   3    0.1000     1.9458   22.6560    62.1770\n",
            "Epoch: 3\n",
            "   4    0.1000     1.7668   27.6460    62.1459\n",
            "Epoch: 4\n",
            "   5    0.1000     1.6487   35.2820    62.1490     1.7016   39.2500     5.8990\n",
            "Epoch: 5\n",
            "   6    0.1000     1.5260   42.6860    62.1015\n",
            "Epoch: 6\n",
            "   7    0.1000     1.3495   51.7180    61.9954\n",
            "Epoch: 7\n",
            "   8    0.1000     1.2388   55.9920    62.0094\n",
            "Epoch: 8\n",
            "   9    0.1000     1.1002   62.2340    62.0931\n",
            "Epoch: 9\n",
            "  10    0.0965     0.9931   66.7760    62.1039     0.9774   68.7600     5.8811\n",
            "Epoch: 10\n",
            "  11    0.0929     0.9177   70.1260    62.0325\n",
            "Epoch: 11\n",
            "  12    0.0894     0.8659   71.8300    62.0409\n",
            "Epoch: 12\n",
            "  13    0.0859     0.7732   75.4340    62.0004\n",
            "Epoch: 13\n",
            "  14    0.0823     0.7201   77.0080    62.1025\n",
            "Epoch: 14\n",
            "  15    0.0788     0.6782   78.5380    61.8326     0.6738   79.7300     5.8540\n",
            "Epoch: 15\n",
            "  16    0.0752     0.6120   80.4360    61.9476\n",
            "Epoch: 16\n",
            "  17    0.0717     0.5880   81.4900    61.8718\n",
            "Epoch: 17\n",
            "  18    0.0682     0.5432   82.7500    61.9676\n",
            "Epoch: 18\n",
            "  19    0.0646     0.5247   83.5440    62.0668\n",
            "Epoch: 19\n",
            "  20    0.0611     0.4799   84.7800    61.9452     0.5361   83.3800     5.8635\n",
            "Epoch: 20\n",
            "  21    0.0576     0.4395   85.9600    62.1393\n",
            "Epoch: 21\n",
            "  22    0.0540     0.4257   86.4460    61.8066\n",
            "Epoch: 22\n",
            "  23    0.0505     0.3895   87.5840    61.8758\n",
            "Epoch: 23\n",
            "  24    0.0470     0.3653   88.3480    62.0465\n",
            "Epoch: 24\n",
            "  25    0.0434     0.3421   89.0440    61.8614     0.4894   84.7000     5.8535\n",
            "Epoch: 25\n",
            "  26    0.0399     0.3148   89.8700    61.7685\n",
            "Epoch: 26\n",
            "  27    0.0364     0.2914   90.6660    61.7309\n",
            "Epoch: 27\n",
            "  28    0.0328     0.2724   91.1540    61.7350\n",
            "Epoch: 28\n",
            "  29    0.0293     0.2474   91.8820    61.6292\n",
            "Epoch: 29\n",
            "  30    0.0258     0.2280   92.4660    61.7204     0.4202   87.4200     5.9011\n",
            "Epoch: 30\n",
            "  31    0.0222     0.2084   93.2340    61.8359\n",
            "Epoch: 31\n",
            "  32    0.0187     0.1903   93.6580    61.6126\n",
            "Epoch: 32\n",
            "  33    0.0151     0.1736   94.2880    61.6235\n",
            "Epoch: 33\n",
            "  34    0.0116     0.1570   94.8580    61.5718\n",
            "Epoch: 34\n",
            "  35    0.0081     0.1398   95.3440    61.7558     0.4156   88.7900     5.8336\n",
            "Epoch: 35\n",
            "  36    0.0045     0.1273   95.7240    61.5821\n",
            "Epoch: 36\n",
            "  37    0.0010     0.1187   95.9800    61.7787\n",
            "Epoch: 37\n",
            "  38    0.0010     0.1159   96.1100    61.7057\n",
            "Epoch: 38\n",
            "  39    0.0010     0.1143   96.1660    61.6761\n",
            "Epoch: 39\n",
            "  40    0.0010     0.1131   96.2540    61.5817     0.4267   88.7600     5.8262\n"
          ]
        }
      ],
      "source": [
        "#BM8 - (2,5)/(4,3)            \n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=2 --weight-man=5 \\\n",
        "--activate-exp=2 --activate-man=5 \\\n",
        "--error-exp=4 --error-man=3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BM8 - (3,4)/(4,3)            \n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=3 --weight-man=4 \\\n",
        "--activate-exp=3 --activate-man=4 \\\n",
        "--error-exp=4 --error-man=3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uYMGCTv98x3",
        "outputId": "d21b2d50-87ca-4363-e5f9-b27dc2354abb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w43_a43_e34\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=3, mantissa=4, tile=48)\n",
            "activate  : BlockMinifloat (exponent=3, mantissa=4, tile=48)\n",
            "error     : BlockMinifloat (exponent=4, mantissa=3, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2371   10.2120    63.7151     2.1215   13.0500     6.0210\n",
            "Epoch: 1\n",
            "   2    0.1000     2.1067   14.8880    62.3192\n",
            "Epoch: 2\n",
            "   3    0.1000     1.9661   18.3900    62.3375\n",
            "Epoch: 3\n",
            "   4    0.1000     1.8890   18.9800    62.3307\n",
            "Epoch: 4\n",
            "   5    0.1000     1.7685   25.8860    62.4192     1.6933   29.5100     5.9655\n",
            "Epoch: 5\n",
            "   6    0.1000     1.6306   34.1980    62.3044\n",
            "Epoch: 6\n",
            "   7    0.1000     1.5369   39.1720    62.3596\n",
            "Epoch: 7\n",
            "   8    0.1000     1.3405   48.4040    62.3064\n",
            "Epoch: 8\n",
            "   9    0.1000     1.2373   52.7380    62.2752\n",
            "Epoch: 9\n",
            "  10    0.0965     1.1999   56.1860    62.3881     1.0863   61.8200     5.9026\n",
            "Epoch: 10\n",
            "  11    0.0929     1.0410   64.4600    62.0919\n",
            "Epoch: 11\n",
            "  12    0.0894     0.9407   69.3340    62.1659\n",
            "Epoch: 12\n",
            "  13    0.0859     0.8679   71.8720    62.0687\n",
            "Epoch: 13\n",
            "  14    0.0823     0.7827   74.7660    62.1007\n",
            "Epoch: 14\n",
            "  15    0.0788     0.7251   76.9980    62.0962     0.7555   76.9000     5.8972\n",
            "Epoch: 15\n",
            "  16    0.0752     0.6770   78.6600    62.2084\n",
            "Epoch: 16\n",
            "  17    0.0717     0.6237   80.1680    61.9994\n",
            "Epoch: 17\n",
            "  18    0.0682     0.5950   81.4080    61.9391\n",
            "Epoch: 18\n",
            "  19    0.0646     0.5509   82.6240    61.9836\n",
            "Epoch: 19\n",
            "  20    0.0611     0.5191   83.6660    62.0315     0.5669   82.9500     5.8892\n",
            "Epoch: 20\n",
            "  21    0.0576     0.4718   85.0220    62.0449\n",
            "Epoch: 21\n",
            "  22    0.0540     0.4399   85.9840    62.0397\n",
            "Epoch: 22\n",
            "  23    0.0505     0.4193   86.7280    62.0723\n",
            "Epoch: 23\n",
            "  24    0.0470     0.3949   87.4260    62.1366\n",
            "Epoch: 24\n",
            "  25    0.0434     0.3627   88.3780    62.0520     0.4853   85.4900     5.8657\n",
            "Epoch: 25\n",
            "  26    0.0399     0.3283   89.3720    62.0020\n",
            "Epoch: 26\n",
            "  27    0.0364     0.3088   90.0360    62.1083\n",
            "Epoch: 27\n",
            "  28    0.0328     0.2900   90.6040    62.2475\n",
            "Epoch: 28\n",
            "  29    0.0293     0.2721   91.0580    62.2152\n",
            "Epoch: 29\n",
            "  30    0.0258     0.2405   92.0880    62.1579     0.4719   86.1100     5.9166\n",
            "Epoch: 30\n",
            "  31    0.0222     0.2254   92.5140    62.5129\n",
            "Epoch: 31\n",
            "  32    0.0187     0.2056   93.2000    62.2353\n",
            "Epoch: 32\n",
            "  33    0.0151     0.1837   93.9620    62.1973\n",
            "Epoch: 33\n",
            "  34    0.0116     0.1705   94.4180    62.3929\n",
            "Epoch: 34\n",
            "  35    0.0081     0.1537   94.9040    62.2947     0.4081   88.6100     5.8748\n",
            "Epoch: 35\n",
            "  36    0.0045     0.1380   95.4880    62.1647\n",
            "Epoch: 36\n",
            "  37    0.0010     0.1310   95.7220    62.1228\n",
            "Epoch: 37\n",
            "  38    0.0010     0.1267   95.7960    62.1385\n",
            "Epoch: 38\n",
            "  39    0.0010     0.1241   95.8400    62.1231\n",
            "Epoch: 39\n",
            "  40    0.0010     0.1245   95.9420    62.3264     0.4166   88.7600     5.8516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiC9hz9cFKdG",
        "outputId": "6b1b633e-5e8f-4d4d-cb95-0e7efcb4e51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w32_a32_e23\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=2, mantissa=3, tile=48)\n",
            "activate  : BlockMinifloat (exponent=2, mantissa=3, tile=48)\n",
            "error     : BlockMinifloat (exponent=3, mantissa=2, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2166   10.6760    78.0727     2.2939   12.9200     7.0583\n",
            "Epoch: 1\n",
            "   2    0.1000     2.0636   17.0400    76.0394\n",
            "Epoch: 2\n",
            "   3    0.1000     1.9106   20.1500    76.3877\n",
            "Epoch: 3\n",
            "   4    0.1000     1.7965   27.0180    76.5619\n",
            "Epoch: 4\n",
            "   5    0.1000     1.6311   33.8420    76.2862     1.6610   35.6700     6.9458\n",
            "Epoch: 5\n",
            "   6    0.1000     1.5440   37.8320    76.7211\n",
            "Epoch: 6\n",
            "   7    0.1000     1.4292   45.9860    76.5766\n",
            "Epoch: 7\n",
            "   8    0.1000     1.3168   50.7820    76.6623\n",
            "Epoch: 8\n",
            "   9    0.1000     1.1628   60.0920    76.7018\n",
            "Epoch: 9\n",
            "  10    0.0965     1.0404   65.3520    76.1474     0.9429   69.2000     7.0240\n",
            "Epoch: 10\n",
            "  11    0.0929     0.9343   69.3180    76.3115\n",
            "Epoch: 11\n",
            "  12    0.0894     0.8688   71.6200    76.6924\n",
            "Epoch: 12\n",
            "  13    0.0859     0.7868   74.9040    76.3343\n",
            "Epoch: 13\n",
            "  14    0.0823     0.7372   76.3740    76.3706\n",
            "Epoch: 14\n",
            "  15    0.0788     0.6821   78.3620    76.2289     0.7778   75.7000     6.8405\n",
            "Epoch: 15\n",
            "  16    0.0752     0.6476   79.7780    76.4614\n",
            "Epoch: 16\n",
            "  17    0.0717     0.5929   81.1500    76.6696\n",
            "Epoch: 17\n",
            "  18    0.0682     0.5650   82.2060    76.6388\n",
            "Epoch: 18\n",
            "  19    0.0646     0.5355   82.9860    76.4898\n",
            "Epoch: 19\n",
            "  20    0.0611     0.4981   84.2060    76.3667     0.6341   80.9600     6.8803\n",
            "Epoch: 20\n",
            "  21    0.0576     0.4531   85.6240    76.1474\n",
            "Epoch: 21\n",
            "  22    0.0540     0.4331   86.3180    76.4946\n",
            "Epoch: 22\n",
            "  23    0.0505     0.3949   87.4240    76.0394\n",
            "Epoch: 23\n",
            "  24    0.0470     0.3828   87.5740    76.3652\n",
            "Epoch: 24\n",
            "  25    0.0434     0.3560   88.6560    76.4217     0.5044   84.3300     7.0255\n",
            "Epoch: 25\n",
            "  26    0.0399     0.3332   89.3180    76.6747\n",
            "Epoch: 26\n",
            "  27    0.0364     0.3022   90.2940    76.5770\n",
            "Epoch: 27\n",
            "  28    0.0328     0.2882   90.7220    76.2549\n",
            "Epoch: 28\n",
            "  29    0.0293     0.2732   91.0620    76.4885\n",
            "Epoch: 29\n",
            "  30    0.0258     0.2475   91.8280    76.3436     0.4449   86.7500     6.8637\n",
            "Epoch: 30\n",
            "  31    0.0222     0.2279   92.5260    76.6806\n",
            "Epoch: 31\n",
            "  32    0.0187     0.2098   93.0200    76.7297\n",
            "Epoch: 32\n",
            "  33    0.0151     0.1927   93.7620    76.6932\n",
            "Epoch: 33\n",
            "  34    0.0116     0.1721   94.2800    76.6370\n",
            "Epoch: 34\n",
            "  35    0.0081     0.1553   94.8760    76.1332     0.4253   88.0300     6.9160\n",
            "Epoch: 35\n",
            "  36    0.0045     0.1435   95.1760    76.5276\n",
            "Epoch: 36\n",
            "  37    0.0010     0.1336   95.5940    76.3368\n",
            "Epoch: 37\n",
            "  38    0.0010     0.1282   95.6320    76.2458\n",
            "Epoch: 38\n",
            "  39    0.0010     0.1318   95.6240    76.1886\n",
            "Epoch: 39\n",
            "  40    0.0010     0.1316   95.5240    76.3167     0.4309   88.5700     7.0743\n"
          ]
        }
      ],
      "source": [
        "#BM6 (2,3)/(3,2)\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=2 --weight-man=3 \\\n",
        "--activate-exp=2 --activate-man=3 \\\n",
        "--error-exp=3 --error-man=2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BM6 (3,2)/(2,3)\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=3 --weight-man=2 \\\n",
        "--activate-exp=3 --activate-man=2 \\\n",
        "--error-exp=2 --error-man=3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWi2K_mI-plE",
        "outputId": "57383f92-f487-481f-fe4c-82e45eae7653"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w23_a23_e32\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=3, mantissa=2, tile=48)\n",
            "activate  : BlockMinifloat (exponent=3, mantissa=2, tile=48)\n",
            "error     : BlockMinifloat (exponent=2, mantissa=3, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2858   10.6780    54.6875     2.2517   15.5100     4.8881\n",
            "Epoch: 1\n",
            "   2    0.1000     2.2661   12.5860    53.2193\n",
            "Epoch: 2\n",
            "   3    0.1000     2.2719   12.0940    53.0572\n",
            "Epoch: 3\n",
            "   4    0.1000     2.3026   11.5500    53.1127\n",
            "Epoch: 4\n",
            "   5    0.1000     2.2514   12.7780    53.0547     2.0965   17.4800     4.8513\n",
            "Epoch: 5\n",
            "   6    0.1000     2.0245   17.6320    53.0739\n",
            "Epoch: 6\n",
            "   7    0.1000     1.9399   18.1220    53.0777\n",
            "Epoch: 7\n",
            "   8    0.1000     1.9026   18.9960    53.0835\n",
            "Epoch: 8\n",
            "   9    0.1000     1.8192   23.9320    53.2083\n",
            "Epoch: 9\n",
            "  10    0.0965     1.7665   26.6000    53.1458     1.7352   28.0300     4.8701\n",
            "Epoch: 10\n",
            "  11    0.0929     1.6886   29.1320    53.0419\n",
            "Epoch: 11\n",
            "  12    0.0894     1.6093   35.2680    53.0099\n",
            "Epoch: 12\n",
            "  13    0.0859     1.5143   38.7820    53.1717\n",
            "Epoch: 13\n",
            "  14    0.0823     1.4034   46.5580    53.1098\n",
            "Epoch: 14\n",
            "  15    0.0788     1.2841   53.7460    52.9741     1.2654   55.5400     4.8573\n",
            "Epoch: 15\n",
            "  16    0.0752     1.1622   59.6840    53.0485\n",
            "Epoch: 16\n",
            "  17    0.0717     1.0892   62.4980    53.1339\n",
            "Epoch: 17\n",
            "  18    0.0682     1.0054   65.9160    53.0855\n",
            "Epoch: 18\n",
            "  19    0.0646     0.9291   69.1680    53.1026\n",
            "Epoch: 19\n",
            "  20    0.0611     0.8466   72.5500    53.1481     0.8581   72.9500     4.8193\n",
            "Epoch: 20\n",
            "  21    0.0576     0.7834   75.1220    53.0238\n",
            "Epoch: 21\n",
            "  22    0.0540     0.7201   77.0460    52.9996\n",
            "Epoch: 22\n",
            "  23    0.0505     0.6854   78.0160    53.1913\n",
            "Epoch: 23\n",
            "  24    0.0470     0.6407   79.5040    53.0956\n",
            "Epoch: 24\n",
            "  25    0.0434     0.5937   80.9400    53.0340     0.6396   80.5100     4.8025\n",
            "Epoch: 25\n",
            "  26    0.0399     0.5637   81.8660    53.1460\n",
            "Epoch: 26\n",
            "  27    0.0364     0.5287   83.1260    53.1056\n",
            "Epoch: 27\n",
            "  28    0.0328     0.4870   84.2820    52.9752\n",
            "Epoch: 28\n",
            "  29    0.0293     0.4565   85.4540    53.1607\n",
            "Epoch: 29\n",
            "  30    0.0258     0.4246   86.2520    53.1118     0.5323   83.9900     4.8229\n",
            "Epoch: 30\n",
            "  31    0.0222     0.3987   86.9420    53.0123\n",
            "Epoch: 31\n",
            "  32    0.0187     0.3684   87.8240    52.9751\n",
            "Epoch: 32\n",
            "  33    0.0151     0.3435   88.5740    52.9144\n",
            "Epoch: 33\n",
            "  34    0.0116     0.3168   89.6680    52.9340\n",
            "Epoch: 34\n",
            "  35    0.0081     0.2958   90.0280    53.0972     0.4685   85.7500     4.7919\n",
            "Epoch: 35\n",
            "  36    0.0045     0.2789   90.6260    53.0561\n",
            "Epoch: 36\n",
            "  37    0.0010     0.2623   91.2920    53.0483\n",
            "Epoch: 37\n",
            "  38    0.0010     0.2536   91.5280    53.0472\n",
            "Epoch: 38\n",
            "  39    0.0010     0.2569   91.4200    53.1104\n",
            "Epoch: 39\n",
            "  40    0.0010     0.2493   91.5700    53.0691     0.4626   86.2600     5.1792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Beyxj8IBU9XX",
        "outputId": "02bfc968-c4dd-47cf-bbda-26c24151064b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w22_a22_e13\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=2, mantissa=2, tile=48)\n",
            "activate  : BlockMinifloat (exponent=2, mantissa=2, tile=48)\n",
            "error     : BlockMinifloat (exponent=3, mantissa=1, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2675   10.2840    54.8589     2.2491   10.0900     5.0796\n",
            "Epoch: 1\n",
            "   2    0.1000     2.1551   14.0200    53.3701\n",
            "Epoch: 2\n",
            "   3    0.1000     1.9569   17.8360    53.5315\n",
            "Epoch: 3\n",
            "   4    0.1000     1.8920   18.8660    53.6340\n",
            "Epoch: 4\n",
            "   5    0.1000     1.8129   23.0140    53.7980     1.8571   20.9200     4.8834\n",
            "Epoch: 5\n",
            "   6    0.1000     1.8327   22.4060    54.8249\n",
            "Epoch: 6\n",
            "   7    0.1000     1.8526   18.9300    55.6863\n",
            "Epoch: 7\n",
            "   8    0.1000     1.8241   19.3760    55.4117\n",
            "Epoch: 8\n",
            "   9    0.1000     1.7820   20.8540    55.4373\n",
            "Epoch: 9\n",
            "  10    0.0965     1.6484   29.3940    55.4302     1.6118   33.5300     5.0607\n",
            "Epoch: 10\n",
            "  11    0.0929     1.5283   36.3560    54.3954\n",
            "Epoch: 11\n",
            "  12    0.0894     1.4253   43.2480    53.9984\n",
            "Epoch: 12\n",
            "  13    0.0859     1.2883   49.5980    54.1393\n",
            "Epoch: 13\n",
            "  14    0.0823     1.1912   53.9960    53.7691\n",
            "Epoch: 14\n",
            "  15    0.0788     1.0820   61.2340    54.0626     1.0746   64.5100     5.0086\n",
            "Epoch: 15\n",
            "  16    0.0752     0.9721   67.5300    54.3599\n",
            "Epoch: 16\n",
            "  17    0.0717     0.8782   71.1780    54.0714\n",
            "Epoch: 17\n",
            "  18    0.0682     0.8333   73.4100    53.9272\n",
            "Epoch: 18\n",
            "  19    0.0646     0.7706   75.4660    53.9436\n",
            "Epoch: 19\n",
            "  20    0.0611     0.7235   77.0080    54.0063     0.7973   75.6500     5.0084\n",
            "Epoch: 20\n",
            "  21    0.0576     0.6620   79.1080    53.9415\n",
            "Epoch: 21\n",
            "  22    0.0540     0.6267   80.3340    54.0152\n",
            "Epoch: 22\n",
            "  23    0.0505     0.5749   81.7520    54.0936\n",
            "Epoch: 23\n",
            "  24    0.0470     0.5460   82.8420    53.5120\n",
            "Epoch: 24\n",
            "  25    0.0434     0.5069   83.7940    53.4997     0.6115   80.9000     4.9476\n",
            "Epoch: 25\n",
            "  26    0.0399     0.4902   84.5020    53.5188\n",
            "Epoch: 26\n",
            "  27    0.0364     0.4586   85.4540    53.7162\n",
            "Epoch: 27\n",
            "  28    0.0328     0.4344   85.9260    53.6697\n",
            "Epoch: 28\n",
            "  29    0.0293     0.4105   86.8100    53.7244\n",
            "Epoch: 29\n",
            "  30    0.0258     0.3718   88.0060    53.7570     0.4841   85.0600     4.9265\n",
            "Epoch: 30\n",
            "  31    0.0222     0.3529   88.5680    54.2842\n",
            "Epoch: 31\n",
            "  32    0.0187     0.3311   89.2440    53.6535\n",
            "Epoch: 32\n",
            "  33    0.0151     0.3085   89.9520    53.8132\n",
            "Epoch: 33\n",
            "  34    0.0116     0.2941   90.4340    53.8057\n",
            "Epoch: 34\n",
            "  35    0.0081     0.2672   91.1640    53.8740     0.4746   85.6800     5.0076\n",
            "Epoch: 35\n",
            "  36    0.0045     0.2523   91.7780    53.7318\n",
            "Epoch: 36\n",
            "  37    0.0010     0.2401   92.0880    53.7243\n",
            "Epoch: 37\n",
            "  38    0.0010     0.2343   92.2440    53.3653\n",
            "Epoch: 38\n",
            "  39    0.0010     0.2364   92.2420    53.5170\n",
            "Epoch: 39\n",
            "  40    0.0010     0.2295   92.5060    53.6518     0.4386   86.8300     4.9534\n"
          ]
        }
      ],
      "source": [
        "#BM5 -- with backward quant (2,2)/(3,1)\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=2 --weight-man=2 \\\n",
        "--activate-exp=2 --activate-man=2 \\\n",
        "--error-exp=3 --error-man=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BM5 -- with backward quant (3,1)/(2,2)\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=3 --weight-man=1 \\\n",
        "--activate-exp=3 --activate-man=1 \\\n",
        "--error-exp=2 --error-man=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyqzPKSbyF4m",
        "outputId": "2fd4ac88-75f9-47c6-bdb0-65877c273c36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w13_a13_e22\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=3, mantissa=1, tile=48)\n",
            "activate  : BlockMinifloat (exponent=3, mantissa=1, tile=48)\n",
            "error     : BlockMinifloat (exponent=2, mantissa=2, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2452    9.9120    54.8770     2.1586   10.0400     4.9734\n",
            "Epoch: 1\n",
            "   2    0.1000     2.1974   12.1040    53.4534\n",
            "Epoch: 2\n",
            "   3    0.1000     1.9724   17.9260    53.4473\n",
            "Epoch: 3\n",
            "   4    0.1000     1.8993   19.8800    53.7216\n",
            "Epoch: 4\n",
            "   5    0.1000     1.8800   20.2100    53.6599     1.8384   24.8100     4.9024\n",
            "Epoch: 5\n",
            "   6    0.1000     1.7556   25.4060    53.6613\n",
            "Epoch: 6\n",
            "   7    0.1000     1.6745   29.3780    53.4592\n",
            "Epoch: 7\n",
            "   8    0.1000     1.5531   35.3520    53.6156\n",
            "Epoch: 8\n",
            "   9    0.1000     1.5879   36.2740    53.6227\n",
            "Epoch: 9\n",
            "  10    0.0965     1.4624   43.9000    53.6712     1.4073   47.5200     4.9371\n",
            "Epoch: 10\n",
            "  11    0.0929     1.3644   50.9980    53.4506\n",
            "Epoch: 11\n",
            "  12    0.0894     1.2187   57.4260    53.5828\n",
            "Epoch: 12\n",
            "  13    0.0859     1.0950   62.4180    53.4869\n",
            "Epoch: 13\n",
            "  14    0.0823     0.9963   66.9140    53.4616\n",
            "Epoch: 14\n",
            "  15    0.0788     0.9515   68.7780    53.6248     1.1045   68.5600     4.9271\n",
            "Epoch: 15\n",
            "  16    0.0752     0.8847   71.8460    53.5466\n",
            "Epoch: 16\n",
            "  17    0.0717     0.8261   73.8140    53.5587\n",
            "Epoch: 17\n",
            "  18    0.0682     0.7863   75.4600    53.6778\n",
            "Epoch: 18\n",
            "  19    0.0646     0.7420   76.9280    53.5757\n",
            "Epoch: 19\n",
            "  20    0.0611     0.6773   79.0460    53.6387     0.7544   76.0700     4.9221\n",
            "Epoch: 20\n",
            "  21    0.0576     0.6335   80.3500    53.4023\n",
            "Epoch: 21\n",
            "  22    0.0540     0.5923   81.5880    53.6576\n",
            "Epoch: 22\n",
            "  23    0.0505     0.5606   82.6420    53.5087\n",
            "Epoch: 23\n",
            "  24    0.0470     0.5359   83.3980    53.4155\n",
            "Epoch: 24\n",
            "  25    0.0434     0.5049   84.1820    53.4561     0.6083   82.0600     4.8907\n",
            "Epoch: 25\n",
            "  26    0.0399     0.4721   85.2840    53.6803\n",
            "Epoch: 26\n",
            "  27    0.0364     0.4500   85.7420    53.7190\n",
            "Epoch: 27\n",
            "  28    0.0328     0.4253   86.4800    53.3419\n",
            "Epoch: 28\n",
            "  29    0.0293     0.3934   87.3240    53.4787\n",
            "Epoch: 29\n",
            "  30    0.0258     0.3750   88.1380    53.4756     0.5430   82.7800     4.8858\n",
            "Epoch: 30\n",
            "  31    0.0222     0.3527   88.6180    53.7031\n",
            "Epoch: 31\n",
            "  32    0.0187     0.3298   89.2560    53.6276\n",
            "Epoch: 32\n",
            "  33    0.0151     0.3143   89.7280    53.5403\n",
            "Epoch: 33\n",
            "  34    0.0116     0.2928   90.4260    53.5715\n",
            "Epoch: 34\n",
            "  35    0.0081     0.2768   90.9000    53.7381     0.4465   86.2300     4.8944\n",
            "Epoch: 35\n",
            "  36    0.0045     0.2592   91.2260    53.7265\n",
            "Epoch: 36\n",
            "  37    0.0010     0.2466   91.9320    53.6150\n",
            "Epoch: 37\n",
            "  38    0.0010     0.2473   91.7000    53.5761\n",
            "Epoch: 38\n",
            "  39    0.0010     0.2423   91.8780    53.6037\n",
            "Epoch: 39\n",
            "  40    0.0010     0.2430   91.8500    53.6433     0.4325   86.9300     4.9274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-PEzQnMsNy2",
        "outputId": "64d408da-3656-405f-ca63-66a1d3afe0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w22_a22_e13\n",
            "Loading dataset CIFAR10 from .\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10/cifar-10-python.tar.gz\n",
            "170499072it [00:02, 58053979.28it/s]                   \n",
            "Extracting ./CIFAR10/cifar-10-python.tar.gz to ./CIFAR10\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=2, mantissa=2, tile=48)\n",
            "activate  : BlockMinifloat (exponent=2, mantissa=2, tile=48)\n",
            "error     : BlockMinifloat (exponent=3, mantissa=1, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.1875   14.0680   106.2918     1.9302   19.7000    12.4316\n",
            "Epoch: 1\n",
            "   2    0.1000     1.9799   18.6840   100.7171\n",
            "Epoch: 2\n",
            "   3    0.1000     1.8375   26.3700   100.6159\n",
            "Epoch: 3\n",
            "   4    0.1000     1.6969   31.4640   100.7339\n",
            "Epoch: 4\n",
            "   5    0.1000     1.5927   36.3860   100.7890     1.5112   40.2800    12.1500\n",
            "Epoch: 5\n",
            "   6    0.1000     1.4989   41.5680   100.7950\n",
            "Epoch: 6\n",
            "   7    0.1000     1.3786   46.9520   100.6643\n",
            "Epoch: 7\n",
            "   8    0.1000     1.2866   51.2260   100.7301\n",
            "Epoch: 8\n",
            "   9    0.1000     1.2247   54.3780   100.7589\n",
            "Epoch: 9\n",
            "  10    0.0965     1.1299   59.1100   100.8027     1.0749   63.3800    12.1620\n",
            "Epoch: 10\n",
            "  11    0.0929     1.0566   64.6300   100.5406\n",
            "Epoch: 11\n",
            "  12    0.0894     1.0300   66.1600   100.4977\n",
            "Epoch: 12\n",
            "  13    0.0859     0.9127   70.6700   100.4475\n",
            "Epoch: 13\n",
            "  14    0.0823     0.8835   71.7420   100.6305\n",
            "Epoch: 14\n",
            "  15    0.0788     0.8226   73.9240   100.2592     0.8135   74.9200    12.1164\n",
            "Epoch: 15\n",
            "  16    0.0752     0.7920   74.8880   100.3283\n",
            "Epoch: 16\n",
            "  17    0.0717     0.7480   76.5740   100.2381\n",
            "Epoch: 17\n",
            "  18    0.0682     0.7090   77.8320   100.3567\n",
            "Epoch: 18\n",
            "  19    0.0646     0.7152   77.5100   100.2664\n",
            "Epoch: 19\n",
            "  20    0.0611     0.6979   78.3820   100.2880     0.6802   78.4100    12.1092\n",
            "Epoch: 20\n",
            "  21    0.0576     0.6402   79.9780   100.4446\n",
            "Epoch: 21\n",
            "  22    0.0540     0.6162   80.6560   100.1019\n",
            "Epoch: 22\n",
            "  23    0.0505     0.6005   81.3920   100.2270\n",
            "Epoch: 23\n",
            "  24    0.0470     0.5762   82.1300   100.2570\n",
            "Epoch: 24\n",
            "  25    0.0434     0.5545   82.5420   100.2488     0.6197   80.7300    12.1397\n",
            "Epoch: 25\n",
            "  26    0.0399     0.5290   83.3960   100.2858\n",
            "Epoch: 26\n",
            "  27    0.0364     0.5041   84.0420   100.1767\n",
            "Epoch: 27\n",
            "  28    0.0328     0.4924   84.4080   100.2085\n",
            "Epoch: 28\n",
            "  29    0.0293     0.4618   85.3520   100.2098\n",
            "Epoch: 29\n",
            "  30    0.0258     0.4476   85.8080   100.1411     0.5540   82.3200    12.1537\n",
            "Epoch: 30\n",
            "  31    0.0222     0.4239   86.3700   100.1803\n",
            "Epoch: 31\n",
            "  32    0.0187     0.4061   86.9120   100.1683\n",
            "Epoch: 32\n",
            "  33    0.0151     0.3872   87.5860    99.9613\n",
            "Epoch: 33\n",
            "  34    0.0116     0.3691   88.2880   100.1381\n",
            "Epoch: 34\n",
            "  35    0.0081     0.3537   88.5640    99.9341     0.5179   84.3800    12.0883\n",
            "Epoch: 35\n",
            "  36    0.0045     0.3457   88.7160   100.0598\n",
            "Epoch: 36\n",
            "  37    0.0010     0.3250   89.3860   100.1186\n",
            "Epoch: 37\n",
            "  38    0.0010     0.3264   89.3280   100.0558\n",
            "Epoch: 38\n",
            "  39    0.0010     0.3223   89.3920    99.9838\n",
            "Epoch: 39\n",
            "  40    0.0010     0.3193   89.6100   100.0865     0.4648   85.5200    12.0588\n"
          ]
        }
      ],
      "source": [
        "#BM5 -- without backward quant\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=2 --weight-man=2 \\\n",
        "--activate-exp=2 --activate-man=2 \\\n",
        "--error-exp=3 --error-man=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeleqjekxncR",
        "outputId": "42a32f45-be0c-460a-c68e-6b46e4d6e8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w42_a42_e24\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=2, mantissa=4, tile=48)\n",
            "activate  : BlockMinifloat (exponent=2, mantissa=4, tile=48)\n",
            "error     : BlockMinifloat (exponent=4, mantissa=2, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2845   11.0320    54.1325     2.2249   18.1200     4.8650\n",
            "Epoch: 1\n",
            "   2    0.1000     2.0384   19.5320    52.9733\n",
            "Epoch: 2\n",
            "   3    0.1000     1.8506   25.8920    53.1215\n",
            "Epoch: 3\n",
            "   4    0.1000     1.7174   30.8460    52.9897\n",
            "Epoch: 4\n",
            "   5    0.1000     1.5830   37.1920    52.8836     1.4120   47.3300     4.8050\n",
            "Epoch: 5\n",
            "   6    0.1000     1.4848   44.0100    52.9803\n",
            "Epoch: 6\n",
            "   7    0.1000     1.3736   48.8700    52.7398\n",
            "Epoch: 7\n",
            "   8    0.1000     1.2497   55.6960    52.9500\n",
            "Epoch: 8\n",
            "   9    0.1000     1.1933   58.4540    52.8399\n",
            "Epoch: 9\n",
            "  10    0.0965     1.0717   64.0040    52.8558     1.0252   65.4100     4.7587\n",
            "Epoch: 10\n",
            "  11    0.0929     0.9728   68.0340    52.9617\n",
            "Epoch: 11\n",
            "  12    0.0894     0.9026   70.7740    52.8137\n",
            "Epoch: 12\n",
            "  13    0.0859     0.8122   73.7720    52.9665\n",
            "Epoch: 13\n",
            "  14    0.0823     0.7807   74.9920    53.0085\n",
            "Epoch: 14\n",
            "  15    0.0788     0.7166   77.3360    52.9252     0.7369   76.3500     4.7897\n",
            "Epoch: 15\n",
            "  16    0.0752     0.6592   79.0860    52.9564\n",
            "Epoch: 16\n",
            "  17    0.0717     0.6266   80.3440    52.9837\n",
            "Epoch: 17\n",
            "  18    0.0682     0.6036   80.9080    52.8339\n",
            "Epoch: 18\n",
            "  19    0.0646     0.5566   82.4640    52.8584\n",
            "Epoch: 19\n",
            "  20    0.0611     0.5162   83.7800    52.8890     0.6225   81.0200     4.8267\n",
            "Epoch: 20\n",
            "  21    0.0576     0.4845   84.5140    52.8325\n",
            "Epoch: 21\n",
            "  22    0.0540     0.4545   85.5600    52.9966\n",
            "Epoch: 22\n",
            "  23    0.0505     0.4148   86.6960    52.9257\n",
            "Epoch: 23\n",
            "  24    0.0470     0.3984   87.3400    52.9297\n",
            "Epoch: 24\n",
            "  25    0.0434     0.3718   87.9340    52.7803     0.5343   84.2700     4.7995\n",
            "Epoch: 25\n",
            "  26    0.0399     0.3540   88.5480    52.8156\n",
            "Epoch: 26\n",
            "  27    0.0364     0.3205   89.5960    52.6807\n",
            "Epoch: 27\n",
            "  28    0.0328     0.3072   90.0840    52.6322\n",
            "Epoch: 28\n",
            "  29    0.0293     0.2830   90.8200    52.6925\n",
            "Epoch: 29\n",
            "  30    0.0258     0.2604   91.4300    52.7111     0.4545   86.2300     4.7585\n",
            "Epoch: 30\n",
            "  31    0.0222     0.2431   92.1300    52.9021\n",
            "Epoch: 31\n",
            "  32    0.0187     0.2226   92.5940    52.8007\n",
            "Epoch: 32\n",
            "  33    0.0151     0.2012   93.3320    52.7844\n",
            "Epoch: 33\n",
            "  34    0.0116     0.1842   93.8980    52.6872\n",
            "Epoch: 34\n",
            "  35    0.0081     0.1683   94.4400    52.8374     0.4364   87.7100     4.7652\n",
            "Epoch: 35\n",
            "  36    0.0045     0.1541   94.7460    52.7175\n",
            "Epoch: 36\n",
            "  37    0.0010     0.1464   95.0700    52.7001\n",
            "Epoch: 37\n",
            "  38    0.0010     0.1402   95.2820    52.8491\n",
            "Epoch: 38\n",
            "  39    0.0010     0.1402   95.3680    52.7738\n",
            "Epoch: 39\n",
            "  40    0.0010     0.1391   95.3340    52.7762     0.4385   88.0400     4.7742\n"
          ]
        }
      ],
      "source": [
        "#BM7 --- (2,4)/(4,2)\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=2 --weight-man=4 \\\n",
        "--activate-exp=2 --activate-man=4 \\\n",
        "--error-exp=4 --error-man=2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BM7 - (3,3)/(3,3)\n",
        "!python3 \"/content/drive/My Drive/block_minifloat/main.py\" --data_path=. --dataset=CIFAR10 --model=VGG16LP --batch_size=256 --wd=1e-4 --lr_init=0.1 --epochs=40 \\\n",
        "--weight-exp=3 --weight-man=3 \\\n",
        "--activate-exp=3 --activate-man=3 \\\n",
        "--error-exp=3 --error-man=3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndhtcj_s-PEZ",
        "outputId": "59ceb925-96fb-4b26-cc63-07050e606c53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint directory ./checkpoints/VGG16LP_CIFAR10_w33_a33_e33\n",
            "Loading dataset CIFAR10 from .\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "weight    : BlockMinifloat (exponent=3, mantissa=3, tile=48)\n",
            "activate  : BlockMinifloat (exponent=3, mantissa=3, tile=48)\n",
            "error     : BlockMinifloat (exponent=3, mantissa=3, tile=48)\n",
            "acc       : Default (pytorch fp32)\n",
            "grad      : Default (pytorch fp32)\n",
            "momentum  : Default (pytorch fp32)\n",
            "Model: VGG16LP\n",
            "Epoch: 0\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "  ep        lr    tr_loss    tr_acc    tr_time    te_loss    te_acc    te_time\n",
            "----  --------  ---------  --------  ---------  ---------  --------  ---------\n",
            "   1    0.1000     2.2959   10.2420    64.0479     2.2881   10.0000     5.9555\n",
            "Epoch: 1\n",
            "   2    0.1000     2.1508   15.9480    62.1609\n",
            "Epoch: 2\n",
            "   3    0.1000     2.0858   16.5360    62.0052\n",
            "Epoch: 3\n",
            "   4    0.1000     1.9252   19.3140    62.2787\n",
            "Epoch: 4\n",
            "   5    0.1000     1.7984   24.8080    62.1607     1.8559   26.3300     5.8698\n",
            "Epoch: 5\n",
            "   6    0.1000     1.7116   29.9660    61.9690\n",
            "Epoch: 6\n",
            "   7    0.1000     1.5998   36.2300    62.0251\n",
            "Epoch: 7\n",
            "   8    0.1000     1.4860   43.8640    62.0726\n",
            "Epoch: 8\n",
            "   9    0.1000     1.3091   53.2700    62.0595\n",
            "Epoch: 9\n",
            "  10    0.0965     1.1748   58.8940    61.9257     1.2501   57.9300     5.8602\n",
            "Epoch: 10\n",
            "  11    0.0929     1.0764   63.0820    61.9935\n",
            "Epoch: 11\n",
            "  12    0.0894     1.0090   66.4480    61.9391\n",
            "Epoch: 12\n",
            "  13    0.0859     0.9084   70.2880    61.9093\n",
            "Epoch: 13\n",
            "  14    0.0823     0.8366   72.7160    61.9478\n",
            "Epoch: 14\n",
            "  15    0.0788     0.7887   74.6840    61.8522     0.7762   74.6300     5.8248\n",
            "Epoch: 15\n",
            "  16    0.0752     0.7152   77.0060    62.1326\n",
            "Epoch: 16\n",
            "  17    0.0717     0.7009   77.5120    61.9881\n",
            "Epoch: 17\n",
            "  18    0.0682     0.6586   79.2760    61.9185\n",
            "Epoch: 18\n",
            "  19    0.0646     0.6148   80.7000    61.9373\n",
            "Epoch: 19\n",
            "  20    0.0611     0.5671   82.0740    62.0427     0.6194   80.2300     5.8490\n",
            "Epoch: 20\n",
            "  21    0.0576     0.5265   83.3520    62.0586\n",
            "Epoch: 21\n",
            "  22    0.0540     0.5003   84.1740    61.8362\n",
            "Epoch: 22\n",
            "  23    0.0505     0.4700   85.0640    61.9174\n",
            "Epoch: 23\n",
            "  24    0.0470     0.4305   86.2480    62.1646\n",
            "Epoch: 24\n",
            "  25    0.0434     0.4072   86.9980    62.1437     0.5285   83.9700     5.9119\n",
            "Epoch: 25\n",
            "  26    0.0399     0.3772   87.9200    62.0802\n",
            "Epoch: 26\n",
            "  27    0.0364     0.3568   88.3920    61.7774\n",
            "Epoch: 27\n",
            "  28    0.0328     0.3299   89.2640    61.8613\n",
            "Epoch: 28\n",
            "  29    0.0293     0.3129   89.9480    61.8458\n",
            "Epoch: 29\n",
            "  30    0.0258     0.2840   90.7320    61.7700     0.4795   85.2100     5.8557\n",
            "Epoch: 30\n",
            "  31    0.0222     0.2663   91.3460    62.0073\n",
            "Epoch: 31\n",
            "  32    0.0187     0.2419   91.8720    61.8525\n",
            "Epoch: 32\n",
            "  33    0.0151     0.2266   92.4740    61.7556\n",
            "Epoch: 33\n",
            "  34    0.0116     0.2079   93.1040    61.7592\n",
            "Epoch: 34\n",
            "  35    0.0081     0.1904   93.6500    61.8634     0.4495   87.3300     5.8291\n",
            "Epoch: 35\n",
            "  36    0.0045     0.1715   94.2500    61.8260\n",
            "Epoch: 36\n",
            "  37    0.0010     0.1610   94.5940    61.7230\n",
            "Epoch: 37\n",
            "  38    0.0010     0.1592   94.6540    61.7084\n",
            "Epoch: 38\n",
            "  39    0.0010     0.1589   94.5640    61.7848\n",
            "Epoch: 39\n",
            "  40    0.0010     0.1575   94.7080    61.8262     0.4417   87.8300     6.2939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting (with backward quantisation)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_ax = [87.7833, 86.4800, 86.5367, 86.9000, 87.4400, 88.4867, 88.6833, 88.6167, 88.7000]\n",
        "x_ax = ['FP32', 'BM5', 'BM5', 'BM6', 'BM6', 'BM7' , 'BM7', 'BM8', 'BM8']\n",
        "\n",
        "annotations = ['FP32', '(2,2)/(3,1)', '(3,1)/(2,2)', '(2,3)/(3,2)', '(3,2)/(2,3)', '(2,4)/(4,2)', '(3,3)/(3,3)', '(2,5)/(4,3)', '(3,4)/(4,3)']\n",
        "\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.scatter(x_ax, y_ax, s=15, color=\"blue\")\n",
        " \n",
        "plt.xlabel('Block Minifloat Config')\n",
        "plt.ylabel('Evaluation Accuracy')\n",
        "plt.title('Precision vs Accuracy')\n",
        "\n",
        "for i, label in enumerate(annotations):\n",
        "    plt.annotate(label, (x_ax[i], y_ax[i]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "raOxV28h7Y_1",
        "outputId": "59d53c1e-d1ad-4f80-9fa9-67ed2a957575"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x864 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAALJCAYAAAAkmpKHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5hWZb3/8fcXUBkU1FRUPIQpnobDCLNFtnlK8RCaeWpbppSpu4O1M8/9TO3sbpe1k8rabvCQGSFZRkqaWQlboUFG1DQlReUgQoqgzHD8/v54npmGYYYZlQeU9X5d13PNOtxr3d/16FUf77Xu9URmIkmSpOLosrELkCRJ0oZlAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASnpbiIgzIuKeTrS7PiK+tCFqkqRNVfgeQEkdiYhZwI7AKuB14G7g/Mx8bWPW9XYVEVsBLwIPZOZxG7seSWrNEUBJnXVCZm4FDAZqgStaN4iIbhu8qrenU4BlwPCI2GlDduw/A0mdYQCU9IZk5hxKI4D9ASIiI+IzEfE08HR52/ERUR8RiyLi/yJiYNPxEbFbRPwyIhZExD8iYlR5+8ciYlJ5OSLiuxHxUkQsjohHI6Kpvxsj4mstznduRMyMiJcj4s6I6NNiX0bEJyPi6XItP4iIaH1NEdEnIhoi4l0tth0QEQsjYrOI2Csi/hQRr5a3je3gaxoJXA/MAD7aqq/3lr+TRRHxQkR8rLy9KiK+ExHPlfuZVN52eETMbnWOWRFxVHn56oi4PSJ+GhGLgY9FxIER8WC5j3kRMSoiNm9xfHVE3Fv+zuZHxBcjYqeIWBoR27VoN7j8z2mzDq5X0juMAVDSGxIRuwHvB6a32PxBYCiwf0QcAIwG/h3YDvgxcGdEbBERXYEJwHNAX2AX4OdtdHM0cCiwN7A18CHgH23U8j7gm+X9O5fP2/p8xwP/Agwstzum9Xkycy7wIKWRuyYfAW7PzBXAV4F7gG2BXYHr2qi5qaZ3A4cDt5Y/Z7Xad3f5+B2AGqC+vPvbwBDgX4F3AZcAq9vrp5UTgduBbcp9rgIuALYHhgFHAp8u19AT+D0wEegD7AXcl5kvAn+k9B01ORP4efk7kLQJMQBK6qxfRcQiYBLwJ+AbLfZ9MzNfzswG4Dzgx5k5JTNXZeZNlG6HHgQcSCl0XJyZr2dmY2ZOaqOvFUBPYF9Kzyo/kZnz2mh3BjA6Mx/OzGXA5cCwiOjbos01mbkoM58H7qcUutryM+DDUBqBBE4vb2uq591An3XU3ORMYEZm/pVSGK0uh2IohcrfZ+ZtmbkiM/+RmfUR0QU4G/iPzJxT/t7+r3xNnfFgZv4qM1dnZkNmTsvMhzJzZWbOohTCDyu3PR54MTO/U76WJZk5pbzvJsojluWw/mHglk7WIOkdxAAoqbM+mJnbZOa7M/PT5bDX5IUWy+8GLizfflxUDo27UQp+uwHPZebKdXWUmX8ARgE/AF6KiJ9ERK82mvahNOrXdNxrlEYKd2nR5sUWy0uBrdrpdjyl8LgzpdHH1cAD5X2XAAFMjYjHI+LsdZR/FqVRuKbb5X+idEsYStf/9zaO2R7o3s6+zmj5/RMRe0fEhIh4sXxb+BvlPtZVA8CvKY3i7gEMB17NzKlvsiZJb2MGQEnrQ8vXCbwAfL0cFps+PTLztvK+3TszUSEzv5+ZQ4D9Kd0KvriNZnMpBU4AImJLSred57zhC8h8hdJt3n+jNFL38yy/JiEzX8zMczOzD6Vb2z+MiL1anyMi/hXoB1xeDl8vUro1/pHyNb8A7NlG9wuBxnb2vQ70aNFHV0q3j9cov9X6j4AngX6Z2Qv4IqUAS7mG97TzHTQCv6A0Cngmjv5JmywDoKT17X+AT0bE0PJkji0jYkT52bOpwDzgmvL27hFxcOsTRMS/lI/fjFIAaqTt5+FuAz4eETURsQWlka4p5dueb8bPKI3gnco/b/8SEadFxK7l1VcoBa626hkJ3EsptNaUP/2BKuA4SiODR0XEhyKiW0RsFxE1mbma0nOT15YnpHSNiGHla3oK6F7+DjejNPt6iw6uoyewGHgtIvYFPtVi3wRg54j4fPm5zJ4RMbTF/puBjwEfwAAobbIMgJLWq8ysA86ldAv3FWAmpUBBZq4CTqA08eB5YDalEbfWelEKkq9QusX7D+C/2ujr98CXKN2+nUdpBO30t1D+nZRG8F7MzEdabP8XYEpEvFZu8x+Z+UzLAyOiO6UJFNeVRwybPs9SClIjy88hvh+4EHiZ0gSQQeVTXAQ8CvylvO8/gS6Z+SqlCRw3UBrZfJ3S97YuF1EaxVxC6XtsnrWcmUso3d49gdLt8aeBI1rsn0wp3D6cmc8haZPki6AlSWuIiD8AP8vMGzZ2LZIqwwAoSWoWEf9C6Tb2buXRQkmbIG8BS5IAiIibKL0j8POGP2nT5gigJElSwTgCKEmSVDCbzI+Gb7/99tm3b9+NXYYkSVKHpk2btjAzW7/Tc4PZZAJg3759qaur29hlSJIkdSgiNuprlrwFLEmSVDAGQEmSpIIxAEqSJBWMAVCSJKlgDICSJEkFYwCUJEkqGAOgJElSwRgAJUmSCsYAKEmSVDAGQEmSpIIxAEqSJBWMAVCSJKlgDICSJEkFYwCUJEkqGAOgJElSwRgAJUmSCsYAKEmSVDAGQEmSpIIxAEqSJBWMAVCSJKlgDICSJEkFYwCUJElqQ0NDA4cddhjPPfccgwcPpqamhurqaq6//vp1Hve5z32Orbbaqnl91KhRjB49unWzLSPifwAi4oCI+N+WOyPiXyJiZUSc2vrAiOgeEVMj4pGIeDwivtxi388jol9H12YAlCRJasPo0aM5+eST2XnnnXnwwQepr69nypQpXHPNNcydO7fNY+rq6njllVfW2Hb22Wdz3XXXtW66NTCxvPxF4PtNOyKiK/CfwD3tlLYMeF9mDgJqgGMj4qDyvh8Bl3R0bQZASZKkNtx6662ceOKJbL755myxxRYALFu2jNWrV7fZftWqVVx88cV861vfWmN7jx496Nu3L1OnTm25uSfw+4joCQzMzEda7PssMB54qa1+suS18upm5U+W1x8AjoqIbuu6NgOgJElSK8uXL+eZZ56hb9++ALzwwgsMHDiQ3XbbjUsvvZQ+ffqsdcyoUaP4wAc+wM4777zWvtraWh544AEAFi5cCKUc9ypQCzzW1C4idgFOojSS166I6BoR9ZRC4r2ZOaV80tXATGDQuo43AEqSJLWycOFCttlmm+b13XbbjRkzZjBz5kxuuukm5s+fv0b7uXPnMm7cOD772c+2eb7evXs33za+5557ABaXd+0MLGjR9HvApeUg167MXJWZNcCuwIER0b/F7peAtRNqCwZASZLW4Y1OBPjEJz7BoEGDGDhwIKeeeiqvvVa6U9fWRICHHnqIc889F4Dp06fziU98AoBf//rXDBw4kJqaGmpra5k0adJa/TQ2NnLggQcyaNAgqqurueqqq5r3nX766Tz99NPr5fqLZP58OPRQ6NULTjmlitdfb1yrTZ8+fejfv3/zaF6T6dOnM3PmTPbaay/69u3L0qVL2WuvvZr3NzY2UlVVBcDdd98N8Gp5VwPQvcWpaoGfR8Qs4FTghxHxwfZqzsxFwP3AsS02dy+ft32ZuUl8hgwZkpIkrW+jRo3K733ve7ls2bJsbGzMzMwlS5bku9/97pwzZ85a7V999dXm5QsuuCC/+c1vZmbm66+/njU1NWu0vfLKK/P222/PzMxTTz016+vrm8+/evXqzMx85JFHcp999lmrn9WrV+eSJUsyM3P58uV54IEH5oMPPpiZmX/84x/znHPOeUvXXUSHHJLZrVsmlP5uvvmu2dDQkC+88EIuXbo0MzNffvnl7NevX86YMSMzM88888ycMmXKWufacsst11g///zz87bbbsvVq1fnwIEDE6jLTIB9gUnZRrYBbgRObbH+ZPnvDsA25eUqSs/9Hd+i3aPATm2ds+njCKAkSevwRicC9OrVCygNsDQ0NBARQNsTAe677z6OOuoolixZwowZMxg0qPTY1lZbbdV83Ouvv9683FJENL9qZMWKFaxYsaK53SGHHMLvf/97Vq5cuT6+gsKor4emr2zlSsg8mkmTJvHEE08wdOhQBg0axGGHHcZFF13EgAEDAJgxY0abzwO2NnnyZIYPH860adM44IADmrdn5pPA1uXJIO2KiO2Bpn8Rdgbuj4gZwF8oPQM4odxuR6AhM19c1/kMgJIktePNTAQA+PjHP85OO+3Ek08+ucYzYa0nAmy22WZsvfXW1NXV0b9//zXOcccdd7DvvvsyYsSItt4hB5RmndbU1NC7d2+GDx/O0KFDAejSpQt77bUXjzzySJvHqW01NdCtPHe2Wzfo3/8z3HTTTQwfPpwZM2bwyCOPMGPGDM477zwAFi9eTL9+/dh1113XOlfTrX8o3R6urq5mu+22Y+LEiRx77LGtm48G/q31xsz8WGbeXl49CPhBefuMzDwgMwdmZv/M/EqLwz4C/LijazUASpLUjjc6EaDJmDFjmDt3Lvvttx9jx45t3t56IsDRRx8NwLx589hhhx3WOMdJJ53Ek08+ya9+9Su+9KUvtdlP165dqa+vZ/bs2UydOpXHHmueTLpGX+qcceNg2DDo2bP09+67B3PEEUewatWqNtv36tWLcePGdXjehQsX8tWvfhWAK664gtNPP711kx9RerdfuzJzQmZ+f11tyhYBN3XUyAAoSVILb2UiQEtdu3bl9NNPZ/z48c3bWk8EaBoJqqqqorFx7X4ADj30UJ555pmmV4e0aZtttuGII45g4sSJzdta9qXO2XFH+POfYfHi0t8ddyy9xLlr165v6bzDhw9vHkVuS2Y2ZuYtb6mTf55rTGZ2eO/fAChJUgunnQYPPghLlkBd3ba89NIqGhsbmT17Ng0NpYmVr7zyCpMmTWKfffYB4KyzzmLq1KlkJjNnzgRKzwDeeeed7Lvvvs3nfuqpp+jfvz+ZyYwZM6ipqQFgv/32az4OYObMmU0P8/Pwww+zbNkytttuO4Dm8y1YsIBFixYBpZnK9957b5t9SW1Z51uiJUkqmtYTATbbrDQRIDO58MILiQgys82JAJnJyJEjWbx4MZnJoEGD+NGP/vk+38mTJ3P11Vc3TwRomrSx77778uqrr7JkyRJ69uzJ+PHjufnmm9lss82oqqpi7NixRAQLFy5sDobz5s1j5MiRrFq1itWrV/OhD32I448/HoD58+dTVVXFTjvttAG/Ob2TGAAlSWqhpqY0ArhyZcuJAN/llltuYcaMGWu1bz0RYPLkyW2et+VEgB/96EdrTQQ4++yzGTt2LOeccw6XXnopl1566VrneOihh/jMZz4DwMCBA5k+fXqbff3sZz/j3//939/QdatYoum/JN7pamtrs66ubmOXIUl6h5s/v3QbuL6+FAbHjYPf/nY0I0eOfEvPgt17773069ev3WfBGhsbGTduHGeeeeab7qPJmDFjOPPMM+nWzXGet6uImJaZtRutfwOgJEnShrWxA6CTQCRJkgrGAChJklQwBkBJkqSCMQBKkiQVjAFQkiSpYAyAkiRJBWMAlCRJKhgDoCRJUhsaGho47LDDmDZtGsOGDaO6upqBAwcyduzYNttfffXV7LLLLtTU1FBTU8Ndd90FwKOPPsrHPvax1s0jIh4uL1RFxJ8iomuLnb0iYnZEjGqrr4j434h4JCJmRMTtEbFVefv5EXF2R9fmK8IlSZLaMHr0aE4++WR69uzJzTffTL9+/Zg7dy5DhgzhmGOOYZtttlnrmAsuuICLLrpojW0DBgxg9uzZPP/88+y+++5Nm7cC7ikvnw38MjNXtTjsq8Cf11HeBZm5GCAirgXOB64BRgOTy3/b5QigJElSG2699VZOPPFE9t57b/r16wdAnz596N27NwsWLHhD5zrhhBP4+c9/3nJTL+Du8vIZwK+bdkTEEGBH/hkQ19Ii/AVQBWR5+1JgVkQcuK56DICSJEmtLF++nGeeeWat326eOnUqy5cvZ88992zzuFGjRjFw4EDOPvtsXnnllebttbW1PPDAAy2b9gL+GBGbA+/JzFkAEdEF+A6w5jBiGyJiDPAisC9wXYtddcAh6zrWAChJkgTMnw+HHgq9esEhhyykZ881b/HOmzePM888kzFjxtCly9oR6lOf+hR///vfqa+vZ+edd+bCCy9s3te7d2/mzp0LwJw5cwBWlkfrtgcWtTjNp4G7MnN2R/Vm5seBPsATwL+12PVSeXu7fAZQkiQJOO00ePBBWLkSpk2rolu3xuZ9ixcvZsSIEXz961/noIMOavP4HXfcsXn53HPP5fjjj29eb2xspKqqCoCJEycCvFre1QB0b3GaYcAhEfFpSs8Jbh4Rr2XmZW31mZmrIuLnwCXAmPLm7uXztssRQEmSJKC+vhT+AFat2pbly1fR2NjI8uXLOemkkzjrrLM49dRT1zjm8ssv54477gBKI4RN7rjjDvr379+8/tRTTzWvlwPgYoDMfAXoGhHdy+tnZObumdmX0m3gm5vCX0TcHBEHRsle5W0BfAB4skVZewOPretaHQGUJEkCamr+OQLYrRtst93RTJo0iRdffJE///nP/OMf/+DGG28E4MYbb6SmpoZHH32UD3zgAwBccskl1NfXExH07duXH//4x83nvv/++xkxYgSrVq1i5syZAI0tur4HeC/w+w5KHAjMBQK4KSJ6lZcfAT7Vot3BwNXrOpEBUJIkCRg3rnQbuL6+FAa/9KXPcNNN3+WWW27hox/9aJvHrFixgmHDhgFwyy23tNlm2bJl1NXV8b3vfY8HH3yQoUOHUl9f37LJD4ALaBUAM/NG4EYovRcQeLrFs4EHt9VXRBwAPJ6Z/1jXtUZmrmv/O0ZtbW3W1dVt7DIkSdImZPTo0YwcOZKuXbt23LgdTz/9NHPmzOHwww9v3hYR0zKztsX62cBNrd4F+IZFxHBKQXHWOtsZACVJkjas1gFwQ3MSiCRJUsEYACVJkgrGAChJklQwBkBJkqSCMQBKkiQVjAFQkiSpYAyAkiRJBWMAlCRJKhgDoCRJUsEYACVJkgrGAChJklQwBkBJkqSCMQBKkiQVjAFQkiSpYAyAkiRJBWMAlCRJKhgDoCRJUsEYACVJkgrGAChJklQwBkBJkqSCMQBKkiQVjAFQkiSpYAyAkiRJBVPRABgRF0TE4xHxWETcFhHdI+LIiHg4IuojYlJE7NXGcX0joqHcpj4irq9knZIktaehoYHDDjuMadOmMWzYMKqrqxk4cCBjx45d53Hf+c53iAgWLlwIwIQJE7jyyivXaDNv3jyOPvro5uXjjz9+jf3PP/88W221Fd/+9rfXOv/SpUsZMWIE++67L9XV1Vx22WXN+0aNGsXo0aPf1PWqGCoWACNiF+BzQG1m9ge6AqcDPwLOyMwa4GfAFe2c4u+ZWVP+fLJSdUqStC6jR4/m5JNPpmfPntx88808/vjjTJw4kc9//vMsWrSozWNeeOEF7rnnHnbffffmbSNGjOA3v/kNS5cubd42ceJEjjnmGACuvfZazj333DXO84UvfIHjjjuu3douuuginnzySaZPn87kyZO5++67ATj77LO57rrr3vQ1a9NX6VvA3YCqiOgG9ADmAgn0Ku/furxNkqS3pVtvvZUTTzyRvffem379+gHQp08fevfuzYIFC9o85oILLuBb3/oWEdG8LSI4/PDDmTBhQvO2iRMnNge88ePHc+yxxzbv+9WvfsUee+xBdXV1m3306NGDI444AoDNN9+cwYMHM3v27OZ9ffv2ZerUqW/hyrUpq1gAzMw5wLeB54F5wKuZeQ9wDnBXRMwGzgSuaecUe0TE9Ij4U0QcUqk6JUlqz/Lly3nmmWfo27fvGtunTp3K8uXL2XPPPdc65te//jW77LILgwYNWmtfbW0tDzzwAACrVq3ib3/7G/vvvz/PPvss2267LVtssQUAr732Gv/5n//JVVdd1ak6Fy1axG9+8xuOPPLINvuSWqvkLeBtgROBPYA+wJYR8VHgAuD9mbkrMAa4to3D5wG7Z+YBwBeAn0VEr9aNIuK8iKiLiLr2/itMkqQ3a+HChWyzzTZrbJs3bx5nnnkmY8aMoUuXNf9vdOnSpXzjG9/gK1/5Spvn6927N3Pnlm58TZkyhaFDhzafc4cddmhud/XVV3PBBRew1VZbdVjjypUr+fCHP8znPvc53vOe97TZl9Ratwqe+yjg2cxcABARvwQOBgZl5pRym7HAxNYHZuYyYFl5eVpE/B3YG6hr1e4nwE8Aamtrs0LXIUkqkPnz4bTToL4eqqureP31xuZ9ixcvZsSIEXz961/noIMOWuvYv//97zz77LPNo3+zZ89m8ODBTJ06lZ122onGxkaqqqoAuPvuu5tv+VZVVdHY+M9+pkyZwu23384ll1zCokWL6NKlC927d+f8889fq8/zzjuPfv368fnPf36N7S37klqrZAB8HjgoInoADcCRlALcaRGxd2Y+BQwHnmh9YETsALycmasi4j1AP+CZCtYqSRJQCn8PPggrV0Jd3bZ06bKKxsZGunTpwkknncRZZ53FqaeeusYxl19+OQceeCAnnXQSL730UvP2vn37UldXx/bbbw/AU089Rf/+/QG47777uOSSSwDYe++9mTVrVvNxLW/dXn311Wy11VbN4e/II4/k5ptvZpddduGKK67g1Vdf5YYbbljrOp566ikOPvjg9fOlaJNTyWcApwC3Aw8Dj5b7+glwLjA+Ih6h9AzgxQAR8YGIaBozPxSYERH15XN8MjNfrlStkiQ1qa8vhT8o/c08mkmTJvGLX/yCP//5z9x4443U1NRQU1NDfX09AI8++ig77bRTh+e+//77GTFiBAsWLKB79+707NkTgC233JI999yTmTNnrvP41atXM3PmTN71rncxe/Zsvv71r/PXv/6VwYMHU1NTs0YQnDx5MsOHD3+T34I2dZUcASQzrwJaP8F6R/nTuu2dwJ3l5fHA+ErWJklSW2pq/jkC2K0b9O//GW666bvccsstfPSjH23zmBUrVjBs2LC1trcc1Zs/fz4NDQ0MGDCAn/70p83v/2ty/vnnc+ONN/K1r31tje1XX3118/Jf//pXTjnlFKqqqth1113JbPvpp+nTp1NdXc12223XyatW0UR7//K809TW1mZdXV3HDSVJWoeWzwDW1MC4cfDb345m5MiRdO3a9U2f9y9/+QubbbYZNTU17ba54YYbOOecc950H03uvfde+vXrt9bsZb19RMS0zKzdaP0bACVJkjasjR0A/S1gSZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAqGgAj4oKIeDwiHouI2yKie0QcGREPR0R9REyKiL3aOfbyiJgZEX+LiGMqWackSVKRVCwARsQuwOeA2szsD3QFTgd+BJyRmTXAz4Ar2jh2/3LbauBY4IcR0bVStUqSJBVJpW8BdwOqIqIb0AOYCyTQq7x/6/K21k4Efp6ZyzLzWWAmcGCFa5UkSSqEbpU6cWbOiYhvA88DDcA9mXlPRJwD3BURDcBi4KA2Dt8FeKjF+uzytjVExHnAeQC77777er4CSZKkTVMlbwFvS2kkbw+gD7BlRHwUuAB4f2buCowBrn2zfWTmTzKzNjNrd9hhh/VRtiRJ0iavkreAjwKezcwFmbkC+CVwMDAoM6eU24wF/rWNY+cAu7VY37W8TZIkSW9RJQPg88BBEdEjIgI4EvgrsHVE7F1uMxx4oo1j7wROj4gtImIPoB8wtYK1SpIkFUYlnwGcEhG3Aw8DK4HpwE8oPc83PiJWA68AZwNExAcozRi+MjMfj4hfUAqMK4HPZOaqStUqSZJUJJGZG7uG9aK2tjbr6uo2dhmSJEkdiohpmVm7sfr3l0AkSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgsLYkpcAACAASURBVDEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgG9C165dqampaf7MmjWLP/7xj2y99dbU1NSw33778eUvfxmAqVOnNrcbNGgQd9xxBwAvvPACRxxxBPvvvz/V1dX893//98a8JEmSVCDdNnYB70RVVVXU19evsW3WrFkccsghTJgwgddff52amhpOOOEE+vfvT11dHd26dWPevHkMGjSIE044gW7duvGd73yHwYMHs2TJEoYMGcLw4cPZf//9N9JVSZKkonAEsAK23HJLhgwZwsyZM+nRowfdupVydmNjIxEBwM4778zgwYMB6NmzJ/vttx9z5szZaDVLkqTiMAC+CQ0NDc23dU866aS19v/jH//goYceorq6GoApU6ZQXV3NgAEDuP7665sDYZNZs2Yxffp0hg4dukHqlyRJxeYt4DehrVvAAA888AAHHHAAXbp04bLLLmsOgEOHDuXxxx/niSeeYOTIkRx33HF0794dgNdee41TTjmF733ve/Tq1WuDXockSSomA2AnzZ8Pp50G9fXQ0FBa33HHNds0PQPYnv3224+tttqKxx57jNraWlasWMEpp5zCGWecwcknn1zhK5AkSSrxFnAnnXYaPPggLFkCq1eX1jvj2WefZeXKlQA899xzPPnkk/Tt25fM5BOf+AT77bcfX/jCFypYuSRJ0poMgJ1UXw/lHNe83hmTJk1i0KBBzc8L/vCHP2T77bdn8uTJ3HLLLfzhD39ofp7wrrvuqkzxkiRJLURmbuwa1ova2tqsq6ur2PkPPbQ0ArhyJXTrBsOGwZ//XLHuJEnSJiwipmVm7cbqv8MRwIgYsCEKebsbN64U+nr2LP0dN25jVyRJkvTmdGYSyA8jYgvgRuDWzHy1siW9Pe24oyN+kiRp09DhCGBmHgKcAewGTIuIn0XE8IpXJkmSpIro1CSQzHwauAK4FDgM+H5EPBkRvrtEkiTpHaYzzwAOjIjvAk8A7wNOyMz9ysvfrXB9kiRJWs868wzgdcANwBczs6FpY2bOjYgrKlaZJEmSKqIzAXAE0JCZqwAiogvQPTOXZuYtFa1OkiRJ611nngH8PVDVYr1HeZskSZLegToTALtn5mtNK+XlHpUrSZIkSZXUmQD4ekQMblqJiCFAwzraS5Ik6W2sM88Afh4YFxFzgQB2Av6tolVJkiSpYjoMgJn5l4jYF9invOlvmbmismVJkiSpUjozAgil8Lc/0B0YHBFk5s2VK0uSJEmV0mEAjIirgMMpBcC7gOOASYABUJIk6R2oM5NATgWOBF7MzI8Dg4CtK1qVJEmSKqYzAbAhM1cDKyOiF/ASsFtly5IkSVKldOYZwLqI2Ab4H2Aa8BrwYEWrkiRJUsWsMwBGRADfzMxFwPURMRHolZkzNkh1kiRJWu/WGQAzMyPiLmBAeX3WhihKkiRJldOZZwAfjoh/qXglkiRJ2iA68wzgUOCMiHgOeJ3Sr4FkZg6saGWSJEmqiM4EwGMqXoUkSZI2mM4EwKx4FZIkSdpgOhMAf0spBAaln4LbA/gbUF3BuiRJklQhHQbAzBzQcj0iBgOfrlhFkiRJqqjOzAJeQ2Y+TGliiCRJkt6BOhwBjIgvtFjtAgwG5lasIkmSJFVUZ54B7NlieSWlZwLHV6YcSZIkVVpnngH88oYoRJIkSRtGh88ARsS9EbFNi/VtI+J3lS1LkiRJldKZSSA7ZOaippXMfAXoXbmSJEmSVEmdCYCrImL3ppWIeDe+HFqSJOkdqzOTQP4fMCki/kTpZdCHAOdVtCpJkiRVTGcmgUwsv/z5oPKmz2fmwsqWJUmSpErpzCSQk4AVmTkhMycAKyPig5UvTZIkSZXQmWcAr8rMV5tWyhNCrqpcSZIkSaqkzgTAttp05tlBSZIkvQ11JgDWRcS1EbFn+fNdYFqlC5MkSVJldCYAfhZYDowtfxqAT1eyKEmSJFVOZ2YBvw5c1rRefifgZ4D/qmBdkiRJqpDOjAASETtExKcj4gHgfmDHypYlSZKkSml3BDAiegInAx8B9gZ+CeyRmbtuoNokSZJUAeu6BfwSMBW4ApiUmVl+J6AkSZLewdZ1C/hyYAvgh8DlEbHnhilJkiRJldRuAMzM72XmQcCJ5U2/AvpExKURsfcGqU6SJEnrXYeTQDLzmcz8RmYOAGqBXsBdFa9MkiRJFdGpWcBNMvOxzPx/mblXpQqSJElSZb2hAChJkqR3PgOgJElSwRgAJUmSCqbDn4KLiIOBq4F3l9sHkJn5nsqWJkmSpEroMAAC/wtcAEwDVlW2HEmSJFVaZwLgq5l5d8UrkSRJ0gbRmQB4f0T8F6XfAl7WtDEzH65YVZIkSaqYzgTAoeW/tS22JfC+9V+OJEmSKq3DAJiZR2yIQiRJkrRhdPgamIjYOiKujYi68uc7EbH1hihOkiRJ619n3gM4GlgCfKj8WQyMqWRRkiRJqpzOPAO4Z2ae0mL9yxFRX6mCJEmSVFmdGQFsiIj3Nq2UXwzdULmSJEmSVEmdGQH8FHBT+bm/AF4GPlbJoiRJklQ5nZkFXA8Miohe5fXFFa9KkiRJFdNuAIyIj2bmTyPiC622A5CZ11a4NkmSJFXAukYAtyz/7dnGvqxALZIkSdoA2g2Amfnj8uLvM3Nyy33liSCSJEl6B+rMLODrOrlNkiRJ7wDregZwGPCvwA6tngPsBXStdGGSJEmqjHU9A7g5sFW5TcvnABcDp1ayKEmSJFXOup4B/BPwp4i4MTOf24A1SZIkqYI68yLopRHxX0A10L1pY2a+r2JVSZIkqWI6MwnkVuBJYA/gy8As4C+dOXlEXBARj0fEYxFxW0R0j4gHIqK+/JkbEb9q59hVLdrd2cnrkSRJUgc6MwK4XWb+b0T8R4vbwh0GwIjYBfgcsH9mNkTEL4DTM/OQFm3GA79u5xQNmVnTifokSZL0BnQmAK4o/50XESOAucC73sD5qyJiBdCjfCwA5Z+Wex/w8c6XK0mSpLeqM7eAvxYRWwMXAhcBNwAXdHRQZs4Bvg08D8wDXs3Me1o0+SBw3zp+W7h7RNRFxEMR8cFO1ClJkqRO6HAEMDMnlBdfBY7o7IkjYlvgRErPDi4CxjX9vnC5yYcphcn2vDsz50TEe4A/RMSjmfn3Vn2cB5wHsPvuu3e2NEmSpELrMABGxBja+O3fzDy7g0OPAp7NzAXl8/yS0oulfxoR2wMHAie1d3B5BJHMfCYi/ggcAPy9VZufAD8BqK2t9feJJUmSOqEzzwBOaLHcnVJom9tO25aeBw6KiB5AA3AkUFfedyowITMb2zqwPHq4NDOXlcPiwcC3OtGnJEmSOtCZW8DjW65HxG3ApE4cNyUibgceBlYC0ymP1gGnA9e0Om8t8MnMPAfYD/hxRKym9JziNZn5144vR5IkSR2JzDd25zQi9gF+m5l7VaakN6e2tjbr6uo6bihJkrSRRcS0zKzdWP135hnAJZSeAYzy3xeBSytclyRJkiqkM7eAe26IQiRJkrRhtBsAI2Lwug7MzIfXfzmSJEmqtHWNAH5nHfuS0q94SJIk6R2m3V8Cycwj1vEx/EkqlIaGBg477DCee+45Bg8eTE1NDdXV1Vx//fVttj/jjDPYZ5996N+/P2effTYrVpR+VXPChAlceeWVa7SdN28eRx99dPPy8ccfD8C9997LkCFDGDBgAEOGDOEPf/hDm3194hOfYNCgQQwcOJBTTz2V1157DYBRo0YxevTo9XL9kjYtnZoFHBH9gf0pvQcQgMy8uYJ1vWHOApZUST/4wQ9YuXIln/rUp8hMtthiC1577TX69+/P//3f/9GnT5812t91110cd9xxAHzkIx/h0EMPbT528ODBTJ48mR49egAwZswYXn75ZS688EIuvvhi3vve93LiiScyffp0dtxxR/r06cNjjz3GMcccw5w5c9aqbfHixfTq1QuAL3zhC/Tu3ZvLLruMpUuXcvDBBzN9+vQKfzuS3qiNPQu4w98CjoirgOvKnyMovZD5AxWuS5LeVm699VZOPPFENt98c7bYYgsAli1bxurVq9ts//73v5+IICI48MADmT17NgARweGHH86ECf98x/7EiRObw+L48eM59thjATjggAOag2V1dTUNDQ0sW7Zsrb6awl9m0tDQQEQA0KNHD/r27cvUqVPXx1cgaRPSYQCk9KsdRwIvZubHgUHA1hWtSpLeRpYvX84zzzxD3759AXjhhRcYOHAgu+22G5deeulao38trVixgltuuaU51AHU1tbywAMPALBq1Sr+9re/sf/++/Pss8+y7bbbNgfMlsaPH8/gwYPb3Afw8Y9/nJ122oknn3ySz372s232JUlNOhMAGzJzNbAyInoBLwG7VbYsSXr7WLhwIdtss03z+m677caMGTOYOXMmN910E/Pnz2/32E9/+tMceuihHHLIIc3bevfuzdy5pV/UnDJlCkOHDgVKz//tsMMOa53j8ccf59JLL+XHP/5xu/2MGTOGuXPnst9++zF27Ng2+5KkJp0JgHURsQ3wP8A0Sj/t9mBFq5KkjWz+fDj0UOjVC045pYrXX1/7p8v79OlD//792x1h+/KXv8yCBQu49tpr19je2NhIVVUVAHfffXfz6GBVVRWNjWv2M3v2bE466SRuvvlm9txzz3XW3LVrV04//XTGj//nL3i27EuSmnQYADPz05m5KDOvB4YDI8u3giVpk3XaafDgg7BkCdTVbctLL62isbGR2bNn09DQAMArr7zCpEmT2GeffQA466yzmp+3u+GGG/jd737HbbfdRpcua/5P7VNPPUX//v0BuO+++zjqqKMA2HvvvZk1a1Zzu0WLFjFixAiuueYaDj744DXO0dRXZjJz5kyg9AzgnXfeyb777ttmX5LUpDOTQO6MiI9ExJaZOSszZ2yIwiRpY6qvh5UrS8srV0Lm0UyaNIknnniCoUOHMmjQIA477DAuuugiBgwYAMCMGTOanwf85Cc/yfz58xk2bBg1NTV85StfaT73/fffz4gRI1iwYAHdu3enZ8/SDy5tueWW7Lnnns2BbtSoUcycOZOvfOUr1NTUUFNTw0svvbRGX5nJyJEjGTBgAAMGDGDevHlrvGZm8uTJDB8+vOLfl6R3lg5/Co7SC6H/DfhmRPwF+DkwITPXvh8iSZuImprSCODKldCtG/Tv/xluuum73HLLLcyYsfZ/By9evJh+/fqx6667ArCyKT22Mn/+fBoaGhgwYAA//elPm9//1+T888/nxhtv5Gtf+xpXXHEFV1xxRYd9TZ48uc2+pk+fTnV1Ndttt90bunZJm75OvQcQICK6Uvr1j3OBYzOzVyULe6N8D6Ck9Wn+/NJt4Pr6UhgcNw5++9vRjBw5kq5du77p8/7lL39hs802o6ampt02N9xwA+ecc86b7qPJvffeS79+/ZpnL0t6+9jY7wHs7Iugq4ATKI0EDqY0AvjZdR+1YRkAJUnSO8XGDoAd3gKOiF8ABwITgVHAn8qvhZEkSdI7UGeeAfxf4MOZuarSxUiSJKny2p0FHBGXAGTm74CTW+37RoXrkiRJUoWs6zUwp7dYvrzVvmORJEnSO9K6AmC0s9zWuiRJkt4h1hUAs53lttYlSZL0DrGuSSCDImIxpdG+qvIy5fXuFa9MkiRJFdFuAMzMN/+mU0mSJL1tdfhbwJIkSdq0GAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAMgJIkSQVjAJQkSSoYA6AkSVLBGAAlSZIKxgAoSZJUMAZASZKkgjEASpIkFYwBUJIkqWAqGgAj4oKIeDwiHouI2yKie0Q8EBH15c/ciPhVO8eOjIiny5+RlaxTkiSpSLpV6sQRsQvwOWD/zGyIiF8Ap2fmIS3ajAd+3cax7wKuAmqBBKZFxJ2Z+Uql6pUkSSqKSt8C7gZURUQ3oAcwt2lHRPQC3ge0NQJ4DHBvZr5cDn33AsdWuFZJkqRCqFgAzMw5wLeB54F5wKuZeU+LJh8E7svMxW0cvgvwQov12eVta4iI8yKiLiLqFixYsP6KlyRJ2oRVLABGxLbAicAeQB9gy4j4aIsmHwZueyt9ZOZPMrM2M2t32GGHt3IqSZKkwqjkLeCjgGczc0FmrgB+CfwrQERsDxwI/LadY+cAu7VY37W8TZIkSW9RJQPg88BBEdEjIgI4EniivO9UYEJmNrZz7O+AoyNi2/JI4tHlbZIkSXqLKvkM4BTgduBh4NFyXz8p7z6dVrd/I6I2Im4oH/sy8FXgL+XPV8rbJEmS9BZFZm7sGtaL2trarKur29hlSJIkdSgipmVm7cbq318CkSRJKhgDoCRJUsEYACVJkgrGAChJklQwBkBJkqSCMQBKkiQVjAFQkiSpYAyAkiRJBWMAlCRJKhgDoCRJUsEYACVJkgrGAChJklQwBkBJkqSCMQBKkiQVjAFQkjqhoaGBww47jGnTpjFs2DCqq6sZOHAgY8eObbP9l770JQYOHEhNTQ1HH300c+fOBWDChAlceeWVa7SdN28eRx99dPPy8ccfD8DUqVOpqamhpqaGQYMGcccdd6zVz9KlSxkxYgT77rsv1dXVXHbZZc37Ro0axejRo9fL9UvatERmbuwa1ova2tqsq6vb2GVI2kT94Ac/YOXKlRx33HFEBP369WPu3LkMGTKEJ554gm222WaN9osXL6ZXr14AfP/73+evf/0r119/PZnJ4MGDmTx5Mj169ABgzJgxvPzyy1x44YVcfPHFvPe97+XEE09k6dKlbL755nTr1o158+YxaNAg5s6dS7du3Zr7Wbp0KVOmTOGII45g+fLlHHnkkXzxi1/kuOOOY+nSpRx88MFMnz59w31Rkjol/n979x6lVXXnafz5CQqFYsQoowRaEgRRqspXrBaJrZAWUFOJBi+T2Ai40ph2okObFbOME8cktCzpdLcal8mYhEYQGW8hdgQj8RIyQkJz07IQUaTBSymrgLQK0Sqgij1/vG+9XUCVCNRFPc9nLRbnss/e+9SuF7/uc95zIlamlCo6q31nACXpQ5gzZw4XXXQRgwYNYuDAgQD06dOH3r17s3nz5r3KN4U/gPfee4+IACAiGDlyJPPnzy/uX7BgARdccAEAc+fO5fzzzwegR48exbBXX19frKO5Hj168IUvfAGAww47jKFDh1JTU1Pc179/f5YtW3bQ5y/pk8UAKEn7sGPHDtavX0///v13275s2TJ27NjBgAEDWjzue9/7Hv369WPOnDlMmTKluL2iooJFixYB0NjYyMsvv8wpp5zChg0b6NWrF926dSuWXbp0KUOGDKGsrIy77757t9m/Pb3zzjvMmzePc889t8W2JKmJAVCS9mHLli17XeLduHEj48eP55577uGQQ1r+p3Tq1Km88cYbjBs3jrvuuqu4vXfv3sV7ApcuXcqwYcOKdR577LG71TFs2DBWr17N8uXLufXWW6mvr2+xrYaGBi6//HImT57M5z73uRbbkqQmBkBJakFtLZxzDhx5JFxySQnvvfdfwWvr1q1UVlYydepUzjzzzH3WNW7cOObOnVtcr6+vp6SkBIDHH3+8eMm3pKSk1YB38sknc8QRR/DCCy+0uP8b3/gGAwcO5Lrrrttte/O2JKmJAVCSWnDZZbBkCWzbBitW9GLTpkbq6+vZsWMHY8eOZcKECVx66aW7HXPjjTcWv6n7yiuvFLf/+te/ZvDgwcX1tWvXUlpaCsDTTz/NqFGjABg0aBCvvvpqsdyGDRtoaGgA4LXXXuOll14qXoY+99xzefPNNwG46aabePfdd7njjjv2Oo/mbUlSEwOgJLWgqgoK2YuGBkhpDIsXL+ahhx7imWeeYebMmcVHtFRVVQGwatUqjjvuOAC++93vUlpaSnl5OU888QQ//vGPi3UvXLiQyspKNm/eTPfu3enZsycAhx9+OAMGDGDdunUALF68mFNPPZVcLsfYsWP56U9/yjHHHMOuXbtYt24dRx99NDU1NUydOpUXX3yRoUOHksvlmD59erGtP/zhD4wePbojfmSSPkZav5tYkjIsl8vPADY0QNeuUFp6DbNm3c7s2bO54oorWjxm586dDB8+HGC3S77N1dbWUldXR1lZGffdd1/x+X9Nrr32WmbOnMktt9zC+PHjGT9+/F51vPjii1xyySWUlJTQt29fWnuc13PPPceQIUP49Kc/vT+nLikDfA6gJLWgtjZ/GbiqKh8GH34YHntsBhMnTqRLly4HXO/y5cs59NBDyeVyrZaZPn06kyZNOuA2mjz55JMMHDhwr28vS+p8nf0cQAOgJElSB+vsAOg9gJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASvuprq6OESNG8NprrzF06FByuRxDhgzh7rvvbrH8XXfdxYknnkhEsGXLluL2+fPnc/PNN+9WduPGjYwZM6a4/KUvfQmAJ598ktNPP52ysjJOP/10fve737XY1rhx4zjppJMoLS3l61//Ojt37my1LUlSdhkApf00Y8YMLr74Yo4//niWLFlCVVUVS5cuZdq0abz11lt7lT/rrLN46qmnOOGEE3bbXllZybx583j//feL2xYsWMB5550HwG233cZVV10FwDHHHMO8efNYtWoVs2bNYvz48S32bdy4cbz00kusWrWKuro6pk+f3mpbkqTsMgBK+2nOnDlcdNFFHHbYYXTr1g2A7du3s2vXrhbLn3baafTv33+v7RHByJEjmT9/fnHbggULuOCCCwCYO3cu559/frGOPn36ADBkyBDq6urYvn37XnV+8YtfJCKICM444wxqampabUuSlF0GQGk/7Nixg/Xr1xcD3RtvvEF5eTn9+vXjhhtuKIa0D6uiooJFixYB0NjYyMsvv8wpp5zChg0b6NWrVzFgNjd37lyGDh3a4r4mO3fuZPbs2cUAuWdbkqRsMwBK+2HLli0cddRRxfV+/fpRXV3NunXrmDVrFrW1tftVX+/evYuXjZcuXcqwYcOA/P1/xx577F7lV69ezQ033MDPfvazD6z3m9/8Jueccw5nn312i21JkrLNACjtQ20tnHMOHHkkXHJJCe+9V79XmT59+lBaWrrfM2z19fWUlJQA8Pjjjxdn7EpKSqiv372dmpoaxo4dy7333suAAQNarfOHP/whmzdv5rbbbmu1LUlSthkApX247DJYsgS2bYMVK3qxaVMj9fX11NTUUFdXB8Dbb7/N4sWLOemkkwCYMGECy5Yt22fda9eupbS0FICnn36aUaNGATBo0CBeffXVYrl33nmHyspKpk2bxllnnbVbHc3bmj59Or/97W+5//77OeSQG6mCzAAAEPZJREFU3T/ezduSJGWbAVDah6oqaGjILzc0QEpjWLx4MWvWrGHYsGGceuqpjBgxguuvv56ysjIAqquri/cD3nnnnfTt25eamhrKy8uZNGlSse6FCxdSWVnJ5s2b6d69Oz179gTg8MMPZ8CAAaxbtw7IP0pm3bp1TJkyhVwuRy6XY9OmTXu1dfXVV1NbW8vw4cPJ5XJMmTJlr7YkSera2R2QPupyufwMYEMDdO0KpaXXMGvW7cyePZvq6uq9ym/dupWBAwfSt29fACZPnszkyZP3KldbW0tdXR1lZWXcd999xef/Nbn22muZOXMmt9xyCzfddBM33XTTPttqaEqqH9CWJEmRUursPrSJioqKtGLFis7uhj6Bamvzl4GrqvJh8OGH4bHHZjBx4kS6dOlywPUuX76cQw89lFwu12qZ6dOn7zZj2J5tSZI6TkSsTClVdFr7BkBJkqSO1dkB0HsAJUmSMsYAKEmSlDEGQEmSpIxp1wAYEd+KiNUR8UJE3B8R3SNvakSsjYg1EbH31yPzxzZGRFXhz6Pt2U9JkqQsabcAGBGfASYDFSmlUqAL8DXgSqAfMDildDLwQCtV1KWUcoU/F7ZXP6X9VVdXx4gRI1i5ciXDhw9nyJAhlJeX8+CDD7ZY/jvf+Q6DBw+mvLycsWPH8s477wCwatUqrrzyyt3K7ty5k6FDh+7WTmNjI6+99hpDhw4ll8sxZMgQ7r777hbbuuuuuzjxxBOJCLZs2VLcPn/+fG6++eY2OHtJ0idBe18C7gqURERXoAfwFvA/gCkppV0AKaVN7dwHqU3NmDGDiy++mJ49e3LvvfeyevVqFixYwHXXXVcMd82NHj2aF154gerqagYNGsStt94KQFlZGTU1Nbz++uvFsosXLy6+6aOpnS5dunD88cezZMkSqqqqWLp0KdOmTWvxvb5nnXUWTz31FCeccMJu2ysrK5k3bx7vv/9+W/4oJEkfU+0WAFNKbwL/DLwObATeTSk9AQwAvhoRKyLi8YgY2EoV3Qtl/j0ivtJSgYj4RqHMis2bN7fLeUh7mjNnDhdddBGDBg1i4MD8r2+fPn3o3bs3Lf0ejhkzhq5d889cP/PMM6mpqSnu+/KXv8wDD/zXJPiCBQu44IILdmsH4LDDDqNbt24AbN++nV27drXYt9NOO43+/fvvtT0iGDlyJPPnzz+AM5YkfdK05yXgXsBFwGeBPsDhEXEF0A2oLzz75hfAjFaqOKFQ5m+AOyJiwJ4FUko/TylVpJQqjj322HY5D6m5HTt2sH79+r1C1rJly9ixYwcDBuz1a7qbGTNmFAMeQEVFBYsWLSquL1y4kJEjR7bYzhtvvEF5eTn9+vXjhhtuKL7+7cPasy1JUna15yXgUcCGlNLmlNJO4FfA54GawjLAI0B5SwcXZhBJKa0Hfg+c1o59lT6ULVu2cNRRR+22bePGjYwfP5577rmHQw5p/SM1depUunbtyrhx44rbevfuXbyU++abb3L00UfTo0ePFtvp168f1dXVrFu3jlmzZlFbW7tffW/eliQp29ozAL4OnBkRPSIigHOBNcC/AV8olBkBrN3zwIjoFRHdCsvHAGcBL7ZjX6VW1dbCOefAkUfCJZeU8N579cV9W7dupbKykqlTp3LmmWe2WsfMmTOZP38+c+bMIf9xyKuvr6ekpATIX/4977zzACgpKaG+vr7Fuvr06UNpael+z+Y1b0uSlG3teQ/gUuCXwLPAqkJbPwemAZdExCrgVmASQERURMT0wuEnAysi4nlgITAtpWQAVKe47DJYsgS2bYMVK3qxaVMj9fX17Nixg7FjxzJhwgQuvfTS3Y658cYbeeSRR4B8sPvRj37Eo48+So8ePXYrt3btWkpLS4vlmi4P9+rVi8bGxmIIrKmpoa6uDoC3336bxYsXc9JJJwEwYcIEli1bts/zaN6WJCnb2vVbwCml76eUBqeUSlNK41NK21NK76SUKlNKZSml4Sml5wtlV6SUJhWW/1jYf2rh739tz35KH6SqChoa8ssNDZDSGBYvXsxDDz3EM888w8yZM8nlcuRyOaqqqoD8I16OO+44AK699lq2bdvG6NGjyeVyXH311cW6Fy5cSGVlJY2Njaxbt47BgwcX940Zk28HYM2aNQwbNoxTTz2VESNGcP3111NWVgZAdXV18X7AO++8k759+1JTU0N5eTmTJk3aqy1Jkrp2dgekj7pcLj8D2NAAXbtCaek1zJp1O7Nnz+aKK65o8ZidO3cyfPhwANatW9dime3bt7NixQruuOMOlixZwrBhw3bbf80113D77bczatQoRo8eTXV19V51bN26lYEDB9K3b18AJk+ezOTJez9bvba2lrq6umJolCRlW6SUOrsPbaKioiKtWLGis7uhT6Da2vxl4KqqfBh8+GF47LEZTJw4kS5duhxwva+88gpvvvkmI0eObLXMjBkH3w7A8uXLOfTQQ8nlcgdVjySpbUTEysLTTjqnfQOgJElSx+rsANjebwKRJEnSR4wBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJQkScoYA6AkSVLGGAAlSZIyxgAoSZKUMQZASZKkjDEASpIkZYwBUJIkKWMipdTZfWgTEbEZeK0DmjoG2NIB7eijx7HPJsc9uxz77OqIsT8hpXRsO7fRqk9MAOwoEbEipVTR2f1Qx3Pss8lxzy7HPruyMPZeApYkScoYA6AkSVLGGAD33887uwPqNI59Njnu2eXYZ9cnfuy9B1CSJCljnAGUJEnKGAOgJElSxhgAgYhojIiqZn/6R8TIiHi3sL4mIr5fKHtGs3LPR8TYwvZ+EbEwIl6MiNUR8fede1b6sJqN//MR8WxEfL6wvX9EpIi4pVnZYyJiZ0TcVVi/MiI2N/udmNRZ56H9dzBjX9j235t95v9vZ5yD9t9BfuZvb/Z5XxsR73TWeWj/HeTY/0Xhv/PPRUR1RHyxs86jLXTt7A58RNSllHLNN0REf2BRSulLEXE4UBUR84AXgIqUUkNEHA88X9jeAHw7pfRsRPQEVkbEkymlFzv2VHQAiuMfEecBtwIjCvs2AJXATYX1y4DVexz/YErp2o7oqNrcAY99RAwEbgTOSim9HRG9O6zXOlgHPO4ppW81LUfE/wRO64gOq80czL/3NwEPpZT+T0ScAvwG6N8RnW4PzgB+CCml94CVwIkppfdTSg2FXd2BVCizMaX0bGF5G7AG+Exn9FcH5Ujg7Wbr7wNrIqLpgaBfBR7q8F6pI+zv2F8F/CSl9DZASmlTh/RSbe1gPvOXA/e3Y9/UvvZ37FPhGIBPAW+1ew/bkTOAeSURUVVY3pBSGtt8Z0R8GjgT+IfC+jBgBnACML5ZIGwq35/8/xUubd9uq400jX934Hjgr/fY/wDwtYioBRrJf+j7NNt/SUScA6wFvpVSeqMD+qy2cTBjPwggIv4AdAF+kFJa0CG91sE62M88EXEC8Fngd+3fXbWhgxn7HwBPFGZ+DwdGdUiP24kBMG+vS8AFZ0fEc8AuYFpKaTVASmkpMCQiTgZmRcTjKaV6gIg4ApgLXJdS2tpB/dfBaX5JYDhwb0SUNtu/gHz4rwUe3OPYecD9KaXtEfF3wCz2/gdFH10HM/ZdgYHASKAv8ExElKWUvCfso+9gxr3J14BfppQa27WnamsHM/aXAzNTSv9SOHZ2RJSmlHZ1RMfbmpeAP9iilNJpKaXTU0p377kzpbQG+DNQChARh5IPf3NSSr/q2K6qLaSUlpB/CfixzbbtIH8LwLeBX+5R/k8ppe2F1enA6R3UVbWx/R17oAZ4NKW0M6W0gfwM8MAO6q7ayAGMe5Ov4eXfj7UDGPu/pXBJuHBs98LxH0sGwP0UEZ+NiK6F5ROAwcCrERHAvwJrUkq3dWYfdeAiYjD5y3l/2mPXvwA3pJT+c4/yxzdbvZD8vZ/6GNrfsQf+jfzsHxFxDPlLwuvbuZtqYwcw7k3H9AKWtH8P1V4OYOxfB84tHHsy+QC4ub372V68BLz//gr4bkTsJH9p+JsppS0R8VfAeGBVs/sJ/1dK6Ted1VF9aM3vAQ1gYkqpMZ/p8wqX//f89i/A5Ii4kPy3wP8TuLKd+6q2dTBj/1tgTES8SP5eoe+klPb8D4k+mg5m3CE/+/dA8lVaH0cHM/bfBn4REd8i/4WQKz/OvwO+Ck6SJCljvAQsSZKUMQZASZKkjDEASpIkZYwBUJIkKWMMgJIkSRljAJTUZiKiMSKqIuL5iHg2Ij5f2N4/Il44wDpfLTxnb19lFu2xraqpzYioiIg7P0Rbf2y2/E8Rsbrw9w8i4voD7P9XCi+Ob23/hIh4ISJWRcRzB9pOoa77I6I6Ir4VEVMi4mP9qipJ7cfnAEpqS81fs3QecCswooPa7hkR/VJKbxQe0lqUUloBrNhXBSmlzzdb/QZwdOEZYT84iH59BZgPvLjnjoi4ALgOGJNSeisiugETDqSRiDgO+MuU0okH0VdJGeEMoKT2ciTw9p4bI6J7RNzTbMbrC4XtXSLinwuzYdWFF643P64kIh6PiKtaae8h4KuF5ctp9pquiBgZEfMLyz+IiBkR8fuIWB8Rk5uV+3Ph70eBI4CVEfFVmomIXET8e6GPj0REr8L2qyJieWH2c25E9CjMgF4I/FNhRnLAHn2+Ebg+pfQWQEppe0rpF/to5/cR8Y8RsSwi1kbE2YW6ngA+U2jn7IiYGRGXFo75YkS8FBErI+LOpp+FpOwyAEpqSyWFAPIS+Xcj/0MLZa4BUkqpjHxQmxUR3cnPuPUHcimlcmBOs2OOAOYB9zcFpBbMBS4uLH+5UL41g4HzgDOA7xfe412UUrqQwmxmSmnPF8LfS/41UeXAKuD7he2/Sin9ZUrpVPKvBPzblNIfgUfJvyUkl1L6jz3qKiX/3tGWtNYOQNeU0hnkZw+btl8I/EehneLl8MLP9mfABSml02n23lNJ2WUAlNSWmkLTYOB84N5o/o6lvL8C7gNIKb0EvEb+PbqjgJ+llBoK+5q/h/PXwD0ppXs/oO0/AW9HxNfIB7D3P6DsY4XZti3AJuC/fZiTi4hPAUellP5fYdMs4JzCcmlELIqIVcA4YMiHqfMA2gH4VeHvleRD8wcZDKxPKW0orN//QYUlZYMBUFK7SCktAY6hbWac/gCc30KY3NODwE/Yd8jZ3my5kba5H3omcG1hZvOH5F8Uvy+rgdMPoK2m/rdV3yVljAFQUruIiMFAF/Izc80tIj9DRkQMAv4CeBl4Evi7iOha2Hd0s2NuJn8/4U/20ewjwI+A3x5s/1uSUnqX/Cxj031344GmWbqewMbC5eRxzQ7bVtjXklvJ3x94HEBEHBYRk/bRzv56GfhcRPQvrH+19aKSssIAKKktNd0DWEV+Nm5iSqlxjzI/BQ4pXCp9ELgypbSd/D2DrwPVEfE88Dd7HPf3hfp/1FrjKaVtKaV/TCntaKsTasFE8qGtGsgBUwrb/zewlPxs5UvNyj8AfKfwhZfdvgSSUvoNcBfwVESsBp4l/+WZD2pnv6SU6oBvAgsiYiX5QPrugdQl6ZMjUkqd3QdJUjuKiCNSSn8uXEL/CfBKSun2zu6XpM7jDKAkffJdVZiVXQ18ivy3giVlmDOAkiRJGeMMoCRJUsYYACVJkjLGAChJkpQxBkBJkqSMMQBKkiRlzP8Hjz2+k34lHDEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Tests"
      ],
      "metadata": {
        "id": "zCjKDb6Ygh3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialising github stuff\n"
      ],
      "metadata": {
        "id": "9qPTU7eRwdOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "git_token = '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'\n",
        "username = 'noshin-islam'\n",
        "password = '123NoshinT#'\n",
        "repository = 'block_minifloat'\n",
        "\n",
        "# !git clone https://{git_token}@github.com/{username}/{repository}\n",
        "# !git status\n",
        "# !git add .\n",
        "\n",
        "!git init\n",
        "!git config --global user.email \"noshon.2012@gmail.com\"\n",
        "!git config --global user.name \"noshin-islam\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68Vv4WPZwhD0",
        "outputId": "7b6bac23-6341-4734-f3e9-c85b4a5e0b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/drive/MyDrive/block_minifloat/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "HH6ytzOBw0e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Testing google colab commit\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToNeVDk0wlO3",
        "outputId": "b62afef8-ea4b-4cd9-d4d2-ab07b19cefcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch feature/remove-backward-quantisation\n",
            "Your branch is ahead of 'origin/feature/remove-backward-quantisation' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://{username}:{password}@github.com/{username}/block_minifloat.git"
      ],
      "metadata": {
        "id": "zIBYFiv3xma3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote rm origin"
      ],
      "metadata": {
        "id": "ZGySfjNpy4pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7xUdPFMwl7E",
        "outputId": "babbd369-0930-429d-de18-e3c6e51ef9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: The current branch feature/remove-backward-quantisation has no upstream branch.\n",
            "To push the current branch and set the remote as upstream, use\n",
            "\n",
            "    git push --set-upstream origin feature/remove-backward-quantisation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VaX1AhqdxYQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bm_inference_test1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}